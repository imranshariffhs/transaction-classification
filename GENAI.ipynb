{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AlsSMC05AXRB"
   },
   "source": [
    "# **Install All Packages**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "qsTyXV4zAg6N",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-generativeai in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (0.3.2)\n",
      "Collecting google-generativeai\n",
      "  Using cached google_generativeai-0.8.5-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting google-ai-generativelanguage==0.6.15 (from google-generativeai)\n",
      "  Using cached google_ai_generativelanguage-0.6.15-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: google-api-core in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-generativeai) (2.25.0rc1)\n",
      "Requirement already satisfied: google-api-python-client in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-generativeai) (2.170.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-generativeai) (2.40.2)\n",
      "Requirement already satisfied: protobuf in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-generativeai) (4.25.7)\n",
      "Requirement already satisfied: pydantic in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-generativeai) (2.10.3)\n",
      "Requirement already satisfied: tqdm in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-generativeai) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-generativeai) (4.13.2)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-api-core->google-generativeai) (1.70.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-api-core->google-generativeai) (2.31.0)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.62.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.4.26)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from rsa<5,>=3.1.4->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from pydantic->google-generativeai) (2.27.1)\n",
      "Using cached google_generativeai-0.8.5-py3-none-any.whl (155 kB)\n",
      "Using cached google_ai_generativelanguage-0.6.15-py3-none-any.whl (1.3 MB)\n",
      "Installing collected packages: google-ai-generativelanguage, google-generativeai\n",
      "\u001b[2K  Attempting uninstall: google-ai-generativelanguage\n",
      "\u001b[2K    Found existing installation: google-ai-generativelanguage 0.4.0\n",
      "\u001b[2K    Uninstalling google-ai-generativelanguage-0.4.0:\n",
      "\u001b[2K      Successfully uninstalled google-ai-generativelanguage-0.4.0\n",
      "\u001b[2K  Attempting uninstall: google-generativeai━━━━━\u001b[0m \u001b[32m0/2\u001b[0m [google-ai-generativelanguage]\n",
      "\u001b[2K    Found existing installation: google-generativeai 0.3.2[0m [google-ai-generativelanguage]\n",
      "\u001b[2K    Uninstalling google-generativeai-0.3.2:━\u001b[0m \u001b[32m0/2\u001b[0m [google-ai-generativelanguage]\n",
      "\u001b[2K      Successfully uninstalled google-generativeai-0.3.2━━━━━━━━━━\u001b[0m \u001b[32m1/2\u001b[0m [google-generativeai]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [google-generativeai]-generativeai]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-google-genai 0.0.6 requires google-generativeai<0.4.0,>=0.3.1, but you have google-generativeai 0.8.5 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed google-ai-generativelanguage-0.6.15 google-generativeai-0.8.5\n",
      "Requirement already satisfied: langchain-community in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (0.3.24)\n",
      "Collecting langchain-core<1.0.0,>=0.3.59 (from langchain-community)\n",
      "  Downloading langchain_core-0.3.65-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.25 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from langchain-community) (0.3.25)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from langchain-community) (2.0.41)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from langchain-community) (2.31.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from langchain-community) (6.0.1)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from langchain-community) (3.12.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from langchain-community) (8.5.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from langchain-community) (2.9.1)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from langchain-community) (0.1.147)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from langchain-community) (0.4.0)\n",
      "Requirement already satisfied: numpy>=1.26.2 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from langchain-community) (1.26.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.2)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from langchain<1.0.0,>=0.3.25->langchain-community) (0.3.8)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from langchain<1.0.0,>=0.3.25->langchain-community) (2.10.3)\n",
      "Collecting langsmith<0.4,>=0.1.125 (from langchain-community)\n",
      "  Using cached langsmith-0.3.45-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.59->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.59->langchain-community) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.59->langchain-community) (4.13.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.59->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.14)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
      "Requirement already satisfied: anyio in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (4.9.0)\n",
      "Requirement already satisfied: certifi in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.9)\n",
      "Requirement already satisfied: idna in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain-community) (2.27.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (2.4.0)\n",
      "Requirement already satisfied: greenlet>=1 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (1.1.2)\n",
      "Requirement already satisfied: mypy_extensions>=0.3.0 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n",
      "Downloading langchain_core-0.3.65-py3-none-any.whl (438 kB)\n",
      "Using cached langsmith-0.3.45-py3-none-any.whl (363 kB)\n",
      "Installing collected packages: langsmith, langchain-core\n",
      "\u001b[2K  Attempting uninstall: langsmith\n",
      "\u001b[2K    Found existing installation: langsmith 0.1.147\n",
      "\u001b[2K    Uninstalling langsmith-0.1.147:\n",
      "\u001b[2K      Successfully uninstalled langsmith-0.1.147\n",
      "\u001b[2K  Attempting uninstall: langchain-core\n",
      "\u001b[2K    Found existing installation: langchain-core 0.1.53\n",
      "\u001b[2K    Uninstalling langchain-core-0.1.53:\n",
      "\u001b[2K      Successfully uninstalled langchain-core-0.1.53\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [langchain-core]m [langchain-core]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-google-genai 0.0.6 requires langchain-core<0.2,>=0.1, but you have langchain-core 0.3.65 which is incompatible.\n",
      "langchain-postgres 0.0.14 requires pgvector<0.4,>=0.2.5, but you have pgvector 0.4.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed langchain-core-0.3.65 langsmith-0.3.45\n",
      "Requirement already satisfied: typesense in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (1.1.1)\n",
      "Requirement already satisfied: requests in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from typesense) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from requests->typesense) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from requests->typesense) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from requests->typesense) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from requests->typesense) (2025.4.26)\n",
      "Requirement already satisfied: langchain in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (0.3.25)\n",
      "Requirement already satisfied: langchain-google-genai in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (0.0.6)\n",
      "Collecting langchain-google-genai\n",
      "  Using cached langchain_google_genai-2.1.5-py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: langchain-community in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (0.3.24)\n",
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.3.25-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from langchain) (0.3.65)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from langchain) (0.3.45)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from langchain) (2.10.3)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from langchain) (2.0.41)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (8.5.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (4.13.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.14)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: anyio in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n",
      "Requirement already satisfied: certifi in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.9)\n",
      "Requirement already satisfied: idna in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2.4.0)\n",
      "Requirement already satisfied: greenlet>=1 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (1.1.2)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from langchain-google-genai) (1.2.0)\n",
      "Collecting google-ai-generativelanguage<0.7.0,>=0.6.18 (from langchain-google-genai)\n",
      "  Using cached google_ai_generativelanguage-0.6.18-py3-none-any.whl.metadata (9.8 kB)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.25.0rc1)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.40.2)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.26.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (4.25.7)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.70.0)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.71.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.62.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (4.9.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from rsa<5,>=3.1.4->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.6.1)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from langchain-community) (3.12.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from langchain-community) (2.9.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from langchain-community) (0.4.0)\n",
      "Requirement already satisfied: numpy>=1.26.2 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from langchain-community) (1.26.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.2)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.4.1)\n",
      "Requirement already satisfied: mypy_extensions>=0.3.0 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
      "Using cached langchain_google_genai-2.1.5-py3-none-any.whl (44 kB)\n",
      "Using cached google_ai_generativelanguage-0.6.18-py3-none-any.whl (1.4 MB)\n",
      "Downloading langchain_community-0.3.25-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: google-ai-generativelanguage, langchain-google-genai, langchain-community\n",
      "\u001b[2K  Attempting uninstall: google-ai-generativelanguage\n",
      "\u001b[2K    Found existing installation: google-ai-generativelanguage 0.4.0\n",
      "\u001b[2K    Uninstalling google-ai-generativelanguage-0.4.0:\n",
      "\u001b[2K      Successfully uninstalled google-ai-generativelanguage-0.4.0\n",
      "\u001b[2K  Attempting uninstall: langchain-google-genai━━\u001b[0m \u001b[32m0/3\u001b[0m [google-ai-generativelanguage]\n",
      "\u001b[2K    Found existing installation: langchain-google-genai 0.0.6 [google-ai-generativelanguage]\n",
      "\u001b[2K    Uninstalling langchain-google-genai-0.0.6:0m \u001b[32m0/3\u001b[0m [google-ai-generativelanguage]\n",
      "\u001b[2K      Successfully uninstalled langchain-google-genai-0.0.60m [google-ai-generativelanguage]\n",
      "\u001b[2K  Attempting uninstall: langchain-community━\u001b[0m \u001b[32m0/3\u001b[0m [google-ai-generativelanguage]\n",
      "\u001b[2K    Found existing installation: langchain-community 0.3.240m [google-ai-generativelanguage]\n",
      "\u001b[2K    Uninstalling langchain-community-0.3.24:\u001b[0m \u001b[32m0/3\u001b[0m [google-ai-generativelanguage]\n",
      "\u001b[2K      Successfully uninstalled langchain-community-0.3.24\u001b[0m [google-ai-generativelanguage]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [langchain-community]ngchain-community]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-generativeai 0.3.2 requires google-ai-generativelanguage==0.4.0, but you have google-ai-generativelanguage 0.6.18 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed google-ai-generativelanguage-0.6.18 langchain-community-0.3.25 langchain-google-genai-2.1.5\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-postgres 0.0.14 requires pgvector<0.4,>=0.2.5, but you have pgvector 0.4.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mRequirement already satisfied: pandas in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (2.3.0)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from pandas) (1.26.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: openpyxl in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (3.1.2)\n",
      "Requirement already satisfied: et-xmlfile in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from openpyxl) (2.0.0)\n",
      "Requirement already satisfied: google-generativeai in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (0.3.2)\n",
      "Collecting google-ai-generativelanguage==0.4.0 (from google-generativeai)\n",
      "  Using cached google_ai_generativelanguage-0.4.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: google-auth in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-generativeai) (2.40.2)\n",
      "Requirement already satisfied: google-api-core in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-generativeai) (2.25.0rc1)\n",
      "Requirement already satisfied: typing-extensions in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-generativeai) (4.13.2)\n",
      "Requirement already satisfied: protobuf in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-generativeai) (4.25.7)\n",
      "Requirement already satisfied: tqdm in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-generativeai) (4.66.1)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-ai-generativelanguage==0.4.0->google-generativeai) (1.26.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-api-core->google-generativeai) (1.70.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-api-core->google-generativeai) (2.31.0)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.4.0->google-generativeai) (1.71.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.4.0->google-generativeai) (1.62.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-auth->google-generativeai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-auth->google-generativeai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-auth->google-generativeai) (4.9.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.4.26)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from rsa<5,>=3.1.4->google-auth->google-generativeai) (0.6.1)\n",
      "Using cached google_ai_generativelanguage-0.4.0-py3-none-any.whl (598 kB)\n",
      "Installing collected packages: google-ai-generativelanguage\n",
      "  Attempting uninstall: google-ai-generativelanguage\n",
      "    Found existing installation: google-ai-generativelanguage 0.6.18\n",
      "    Uninstalling google-ai-generativelanguage-0.6.18:\n",
      "      Successfully uninstalled google-ai-generativelanguage-0.6.18\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-google-genai 2.1.5 requires google-ai-generativelanguage<0.7.0,>=0.6.18, but you have google-ai-generativelanguage 0.4.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed google-ai-generativelanguage-0.4.0\n",
      "Requirement already satisfied: python-dotenv in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (1.0.0)\n",
      "Requirement already satisfied: qdrant-client in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (1.14.2)\n",
      "Requirement already satisfied: grpcio>=1.41.0 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from qdrant-client) (1.71.0)\n",
      "Requirement already satisfied: httpx>=0.20.0 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from httpx[http2]>=0.20.0->qdrant-client) (0.28.1)\n",
      "Requirement already satisfied: numpy>=1.21 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from qdrant-client) (1.26.3)\n",
      "Requirement already satisfied: portalocker<3.0.0,>=2.7.0 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from qdrant-client) (2.10.1)\n",
      "Requirement already satisfied: protobuf>=3.20.0 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from qdrant-client) (4.25.7)\n",
      "Requirement already satisfied: pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from qdrant-client) (2.10.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.14 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from qdrant-client) (2.4.0)\n",
      "Requirement already satisfied: anyio in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (4.9.0)\n",
      "Requirement already satisfied: certifi in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (1.0.9)\n",
      "Requirement already satisfied: idna in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (0.16.0)\n",
      "Requirement already satisfied: h2<5,>=3 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from httpx[http2]>=0.20.0->qdrant-client) (4.2.0)\n",
      "Requirement already satisfied: hyperframe<7,>=6.1 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client) (6.1.0)\n",
      "Requirement already satisfied: hpack<5,>=4.1 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client) (4.1.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant-client) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant-client) (2.27.1)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant-client) (4.13.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from anyio->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from anyio->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (1.3.1)\n",
      "Requirement already satisfied: python-dotenv in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (1.0.0)\n",
      "Requirement already satisfied: pgvector in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (0.4.1)\n",
      "Requirement already satisfied: psycopg2-binary in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (2.9.10)\n",
      "Requirement already satisfied: numpy in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from pgvector) (1.26.3)\n",
      "Requirement already satisfied: timescale-vector in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (0.0.7)\n",
      "Requirement already satisfied: asyncpg in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from timescale-vector) (0.30.0)\n",
      "Requirement already satisfied: psycopg2 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from timescale-vector) (2.9.10)\n",
      "Requirement already satisfied: pgvector in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from timescale-vector) (0.4.1)\n",
      "Requirement already satisfied: async-timeout>=4.0.3 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from asyncpg->timescale-vector) (4.0.3)\n",
      "Requirement already satisfied: numpy in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from pgvector->timescale-vector) (1.26.3)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.4.0 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (0.4.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.4.0) (2.25.0rc1)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-ai-generativelanguage==0.4.0) (1.26.1)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-ai-generativelanguage==0.4.0) (4.25.7)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.4.0) (1.70.0)\n",
      "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.4.0) (2.40.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.4.0) (2.31.0)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.4.0) (1.71.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.4.0) (1.62.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-auth<3.0.0,>=2.14.1->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.4.0) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-auth<3.0.0,>=2.14.1->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.4.0) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-auth<3.0.0,>=2.14.1->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.4.0) (4.9.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.4.0) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.4.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.4.0) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.4.0) (2025.4.26)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from rsa<5,>=3.1.4->google-auth<3.0.0,>=2.14.1->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.4.0) (0.6.1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install --upgrade google-generativeai\n",
    "!pip install langchain-google-genai --quiet\n",
    "!pip install langchain-community\n",
    "!pip install typesense\n",
    "!pip install -U langchain langchain-google-genai langchain-community\n",
    "!pip install -qU langchain_postgres\n",
    "!pip install -qU duckduckgo-search langchain-community\n",
    "!pip install --upgrade --quiet  lark pgvector psycopg2-binary\n",
    "!pip install pandas\n",
    "!pip install openpyxl\n",
    "!pip install google-generativeai\n",
    "!pip install python-dotenv\n",
    "!pip install qdrant-client\n",
    "!pip install python-dotenv\n",
    "!pip install pgvector psycopg2-binary\n",
    "!pip install timescale-vector\n",
    "!pip install google-ai-generativelanguage==0.4.0\n",
    "\n",
    "#get_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
      "Requirement already satisfied: torch in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (2.5.1+cu121)\n",
      "Requirement already satisfied: torchvision in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (0.20.1+cu121)\n",
      "Requirement already satisfied: torchaudio in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (2.5.1+cu121)\n",
      "Requirement already satisfied: filelock in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: networkx in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from torch) (2025.5.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==3.1.0 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from torch) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.6.85)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from torchvision) (1.26.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: torch in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (2.5.1+cu121)\n",
      "Collecting torch\n",
      "  Using cached torch-2.7.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (29 kB)\n",
      "Requirement already satisfied: torchvision in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (0.20.1+cu121)\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.22.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: torchaudio in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (2.5.1+cu121)\n",
      "Collecting torchaudio\n",
      "  Using cached torchaudio-2.7.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: filelock in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from torch) (4.13.2)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: networkx in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from torch) (2025.5.1)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.6.77 (from torch)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.6.80 (from torch)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch)\n",
      "  Using cached nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.6.4.1 (from torch)\n",
      "  Using cached nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.0.4 (from torch)\n",
      "  Using cached nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.7.77 (from torch)\n",
      "  Using cached nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch)\n",
      "  Using cached nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.4.2 (from torch)\n",
      "  Using cached nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from torch) (0.6.3)\n",
      "Collecting nvidia-nccl-cu12==2.26.2 (from torch)\n",
      "  Using cached nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.6.77 (from torch)\n",
      "  Using cached nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from torch) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from torch) (1.11.1.6)\n",
      "Collecting triton==3.3.1 (from torch)\n",
      "  Using cached triton-3.3.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from triton==3.3.1->torch) (80.9.0)\n",
      "Requirement already satisfied: numpy in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from torchvision) (1.26.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from jinja2->torch) (3.0.2)\n",
      "Using cached torch-2.7.1-cp310-cp310-manylinux_2_28_x86_64.whl (821.2 MB)\n",
      "Using cached nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n",
      "Using cached nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n",
      "Using cached nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n",
      "Using cached nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n",
      "Using cached nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n",
      "Using cached nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n",
      "Using cached nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
      "Using cached nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n",
      "Using cached nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n",
      "Using cached nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n",
      "Using cached nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "Using cached triton-3.3.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.6 MB)\n",
      "Using cached torchvision-0.22.1-cp310-cp310-manylinux_2_28_x86_64.whl (7.5 MB)\n",
      "Using cached torchaudio-2.7.1-cp310-cp310-manylinux_2_28_x86_64.whl (3.5 MB)\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Installing collected packages: triton, sympy, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchvision, torchaudio\n",
      "\u001b[2K  Attempting uninstall: triton\n",
      "\u001b[2K    Found existing installation: triton 3.1.0\n",
      "\u001b[2K    Uninstalling triton-3.1.0:\n",
      "\u001b[2K      Successfully uninstalled triton-3.1.0\n",
      "\u001b[2K  Attempting uninstall: sympy━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 0/16\u001b[0m [triton]\n",
      "\u001b[2K    Found existing installation: sympy 1.13.1[0m \u001b[32m 0/16\u001b[0m [triton]\n",
      "\u001b[2K    Uninstalling sympy-1.13.1:━━━━━━━━━━━━━━\u001b[0m \u001b[32m 0/16\u001b[0m [triton]\n",
      "\u001b[2K      Successfully uninstalled sympy-1.13.1━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/16\u001b[0m [sympy]\n",
      "\u001b[2K  Attempting uninstall: nvidia-nvtx-cu12━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/16\u001b[0m [sympy]\n",
      "\u001b[2K    Found existing installation: nvidia-nvtx-cu12 12.1.105━━━━\u001b[0m \u001b[32m 1/16\u001b[0m [sympy]\n",
      "\u001b[2K    Uninstalling nvidia-nvtx-cu12-12.1.105:━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/16\u001b[0m [sympy]\n",
      "\u001b[2K      Successfully uninstalled nvidia-nvtx-cu12-12.1.105━━━━━━\u001b[0m \u001b[32m 1/16\u001b[0m [sympy]\n",
      "\u001b[2K  Attempting uninstall: nvidia-nccl-cu12━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/16\u001b[0m [sympy]\n",
      "\u001b[2K    Found existing installation: nvidia-nccl-cu12 2.21.5━━━━━━\u001b[0m \u001b[32m 1/16\u001b[0m [sympy]\n",
      "\u001b[2K    Uninstalling nvidia-nccl-cu12-2.21.5:━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/16\u001b[0m [sympy]\n",
      "\u001b[2K      Successfully uninstalled nvidia-nccl-cu12-2.21.5━━━━━━━━\u001b[0m \u001b[32m 1/16\u001b[0m [sympy]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cusparse-cu12━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/16\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cusparse-cu12 12.1.0.1060m \u001b[32m 3/16\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cusparse-cu12-12.1.0.106:━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/16\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cusparse-cu12-12.1.0.106\u001b[0m \u001b[32m 3/16\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-curand-cu12━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/16\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-curand-cu12 10.3.2.106\u001b[0m \u001b[32m 4/16\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-curand-cu12-10.3.2.106:━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/16\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-curand-cu12-10.3.2.106━━\u001b[0m \u001b[32m 4/16\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cufft-cu12━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/16\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cufft-cu12 11.0.2.54━━\u001b[0m \u001b[32m 5/16\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cufft-cu12-11.0.2.54:━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/16\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cufft-cu12-11.0.2.54━━━━\u001b[0m \u001b[32m 5/16\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-runtime-cu12━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/16\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-runtime-cu12 12.1.105 \u001b[32m 6/16\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cuda-runtime-cu12-12.1.105:━━━━━━━━━━━\u001b[0m \u001b[32m 6/16\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-runtime-cu12-12.1.1050m \u001b[32m 6/16\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-nvrtc-cu12━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/16\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-nvrtc-cu12 12.1.1050m \u001b[32m 6/16\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cuda-nvrtc-cu12-12.1.105:━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/16\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.1.105\u001b[0m \u001b[32m 6/16\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-cupti-cu12m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/16\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-cupti-cu12 12.1.1050m \u001b[32m 8/16\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cuda-cupti-cu12-12.1.105:━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/16\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-cupti-cu12-12.1.105\u001b[0m \u001b[32m 8/16\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cublas-cu12m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/16\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cublas-cu12 12.1.3.1━━\u001b[0m \u001b[32m 8/16\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cublas-cu12-12.1.3.1:━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/16\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cublas-cu12-12.1.3.1━━━━\u001b[0m \u001b[32m 8/16\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cusolver-cu12[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/16\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cusolver-cu12 11.4.5.1070m \u001b[32m10/16\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cusolver-cu12-11.4.5.107:━━━━━━━━━━━━━\u001b[0m \u001b[32m10/16\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cusolver-cu12-11.4.5.107\u001b[0m \u001b[32m10/16\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cudnn-cu1291m╸\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m11/16\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cudnn-cu12 9.1.0.70━━━\u001b[0m \u001b[32m11/16\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cudnn-cu12-9.1.0.70:m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m11/16\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cudnn-cu12-9.1.0.70━━━━━\u001b[0m \u001b[32m11/16\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K  Attempting uninstall: torch━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m12/16\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K    Found existing installation: torch 2.5.1+cu12190m━━━━━━━━━\u001b[0m \u001b[32m12/16\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K    Uninstalling torch-2.5.1+cu121:━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m13/16\u001b[0m [torch]nn-cu12]\n",
      "\u001b[2K      Successfully uninstalled torch-2.5.1+cu121m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m13/16\u001b[0m [torch]\n",
      "\u001b[2K  Attempting uninstall: torchvision━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m13/16\u001b[0m [torch]\n",
      "\u001b[2K    Found existing installation: torchvision 0.20.1+cu121━━━━━\u001b[0m \u001b[32m13/16\u001b[0m [torch]\n",
      "\u001b[2K    Uninstalling torchvision-0.20.1+cu121:91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m13/16\u001b[0m [torch]\n",
      "\u001b[2K      Successfully uninstalled torchvision-0.20.1+cu121━━━━━━━\u001b[0m \u001b[32m13/16\u001b[0m [torch]\n",
      "\u001b[2K  Attempting uninstall: torchaudio━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m14/16\u001b[0m [torchvision]\n",
      "\u001b[2K    Found existing installation: torchaudio 2.5.1+cu12190m━━━━\u001b[0m \u001b[32m14/16\u001b[0m [torchvision]\n",
      "\u001b[2K    Uninstalling torchaudio-2.5.1+cu121:[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m14/16\u001b[0m [torchvision]\n",
      "\u001b[2K      Successfully uninstalled torchaudio-2.5.1+cu121\u001b[90m━━━━\u001b[0m \u001b[32m14/16\u001b[0m [torchvision]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16/16\u001b[0m [torchaudio]6\u001b[0m [torchaudio]\n",
      "\u001b[1A\u001b[2KSuccessfully installed nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-nccl-cu12-2.26.2 nvidia-nvtx-cu12-12.6.77 sympy-1.14.0 torch-2.7.1 torchaudio-2.7.1 torchvision-0.22.1 triton-3.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "!pip install --upgrade torch torchvision torchaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: google-generativeai 0.3.2\n",
      "Uninstalling google-generativeai-0.3.2:\n",
      "  Successfully uninstalled google-generativeai-0.3.2\n",
      "Found existing installation: google-ai-generativelanguage 0.4.0\n",
      "Uninstalling google-ai-generativelanguage-0.4.0:\n",
      "  Successfully uninstalled google-ai-generativelanguage-0.4.0\n",
      "Found existing installation: langchain-google-genai 2.1.5\n",
      "Uninstalling langchain-google-genai-2.1.5:\n",
      "  Successfully uninstalled langchain-google-genai-2.1.5\n",
      "Collecting google-generativeai==0.3.2\n",
      "  Using cached google_generativeai-0.3.2-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting google-ai-generativelanguage==0.4.0 (from google-generativeai==0.3.2)\n",
      "  Using cached google_ai_generativelanguage-0.4.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: google-auth in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-generativeai==0.3.2) (2.40.2)\n",
      "Requirement already satisfied: google-api-core in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-generativeai==0.3.2) (2.25.0rc1)\n",
      "Requirement already satisfied: typing-extensions in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-generativeai==0.3.2) (4.13.2)\n",
      "Requirement already satisfied: protobuf in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-generativeai==0.3.2) (4.25.7)\n",
      "Requirement already satisfied: tqdm in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-generativeai==0.3.2) (4.66.1)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-ai-generativelanguage==0.4.0->google-generativeai==0.3.2) (1.26.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-api-core->google-generativeai==0.3.2) (1.70.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-api-core->google-generativeai==0.3.2) (2.31.0)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.4.0->google-generativeai==0.3.2) (1.71.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.4.0->google-generativeai==0.3.2) (1.62.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-auth->google-generativeai==0.3.2) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-auth->google-generativeai==0.3.2) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-auth->google-generativeai==0.3.2) (4.9.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai==0.3.2) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai==0.3.2) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai==0.3.2) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai==0.3.2) (2025.4.26)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from rsa<5,>=3.1.4->google-auth->google-generativeai==0.3.2) (0.6.1)\n",
      "Using cached google_generativeai-0.3.2-py3-none-any.whl (146 kB)\n",
      "Using cached google_ai_generativelanguage-0.4.0-py3-none-any.whl (598 kB)\n",
      "Installing collected packages: google-ai-generativelanguage, google-generativeai\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [google-generativeai]ogle-generativeai]\n",
      "\u001b[1A\u001b[2KSuccessfully installed google-ai-generativelanguage-0.4.0 google-generativeai-0.3.2\n",
      "Collecting google-ai-generativelanguage==0.3.1\n",
      "  Using cached google_ai_generativelanguage-0.3.1-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.3.1) (2.25.0rc1)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-ai-generativelanguage==0.3.1) (1.26.1)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-ai-generativelanguage==0.3.1) (4.25.7)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.3.1) (1.70.0)\n",
      "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.3.1) (2.40.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.3.1) (2.31.0)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.3.1) (1.71.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.3.1) (1.62.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-auth<3.0.0,>=2.14.1->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.3.1) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-auth<3.0.0,>=2.14.1->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.3.1) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-auth<3.0.0,>=2.14.1->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.3.1) (4.9.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.3.1) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.3.1) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.3.1) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.3.1) (2025.4.26)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from rsa<5,>=3.1.4->google-auth<3.0.0,>=2.14.1->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.3.1) (0.6.1)\n",
      "Using cached google_ai_generativelanguage-0.3.1-py3-none-any.whl (113 kB)\n",
      "Installing collected packages: google-ai-generativelanguage\n",
      "  Attempting uninstall: google-ai-generativelanguage\n",
      "    Found existing installation: google-ai-generativelanguage 0.4.0\n",
      "    Uninstalling google-ai-generativelanguage-0.4.0:\n",
      "      Successfully uninstalled google-ai-generativelanguage-0.4.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-generativeai 0.3.2 requires google-ai-generativelanguage==0.4.0, but you have google-ai-generativelanguage 0.3.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed google-ai-generativelanguage-0.3.1\n",
      "Collecting langchain-google-genai==0.0.6\n",
      "  Using cached langchain_google_genai-0.0.6-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: google-generativeai<0.4.0,>=0.3.1 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from langchain-google-genai==0.0.6) (0.3.2)\n",
      "Collecting langchain-core<0.2,>=0.1 (from langchain-google-genai==0.0.6)\n",
      "  Using cached langchain_core-0.1.53-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting google-ai-generativelanguage==0.4.0 (from google-generativeai<0.4.0,>=0.3.1->langchain-google-genai==0.0.6)\n",
      "  Using cached google_ai_generativelanguage-0.4.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: google-auth in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-generativeai<0.4.0,>=0.3.1->langchain-google-genai==0.0.6) (2.40.2)\n",
      "Requirement already satisfied: google-api-core in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-generativeai<0.4.0,>=0.3.1->langchain-google-genai==0.0.6) (2.25.0rc1)\n",
      "Requirement already satisfied: typing-extensions in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-generativeai<0.4.0,>=0.3.1->langchain-google-genai==0.0.6) (4.13.2)\n",
      "Requirement already satisfied: protobuf in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-generativeai<0.4.0,>=0.3.1->langchain-google-genai==0.0.6) (4.25.7)\n",
      "Requirement already satisfied: tqdm in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-generativeai<0.4.0,>=0.3.1->langchain-google-genai==0.0.6) (4.66.1)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-ai-generativelanguage==0.4.0->google-generativeai<0.4.0,>=0.3.1->langchain-google-genai==0.0.6) (1.26.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-api-core->google-generativeai<0.4.0,>=0.3.1->langchain-google-genai==0.0.6) (1.70.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-api-core->google-generativeai<0.4.0,>=0.3.1->langchain-google-genai==0.0.6) (2.31.0)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.4.0->google-generativeai<0.4.0,>=0.3.1->langchain-google-genai==0.0.6) (1.71.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.4.0->google-generativeai<0.4.0,>=0.3.1->langchain-google-genai==0.0.6) (1.62.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-auth->google-generativeai<0.4.0,>=0.3.1->langchain-google-genai==0.0.6) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-auth->google-generativeai<0.4.0,>=0.3.1->langchain-google-genai==0.0.6) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from google-auth->google-generativeai<0.4.0,>=0.3.1->langchain-google-genai==0.0.6) (4.9.1)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from langchain-core<0.2,>=0.1->langchain-google-genai==0.0.6) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from langchain-core<0.2,>=0.1->langchain-google-genai==0.0.6) (1.33)\n",
      "Collecting langsmith<0.2.0,>=0.1.0 (from langchain-core<0.2,>=0.1->langchain-google-genai==0.0.6)\n",
      "  Using cached langsmith-0.1.147-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from langchain-core<0.2,>=0.1->langchain-google-genai==0.0.6) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from langchain-core<0.2,>=0.1->langchain-google-genai==0.0.6) (2.10.3)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from langchain-core<0.2,>=0.1->langchain-google-genai==0.0.6) (8.5.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2,>=0.1->langchain-google-genai==0.0.6) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2,>=0.1->langchain-google-genai==0.0.6) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2,>=0.1->langchain-google-genai==0.0.6) (3.10.14)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2,>=0.1->langchain-google-genai==0.0.6) (1.0.0)\n",
      "Requirement already satisfied: anyio in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-core<0.2,>=0.1->langchain-google-genai==0.0.6) (4.9.0)\n",
      "Requirement already satisfied: certifi in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-core<0.2,>=0.1->langchain-google-genai==0.0.6) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-core<0.2,>=0.1->langchain-google-genai==0.0.6) (1.0.9)\n",
      "Requirement already satisfied: idna in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-core<0.2,>=0.1->langchain-google-genai==0.0.6) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-core<0.2,>=0.1->langchain-google-genai==0.0.6) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from pydantic<3,>=1->langchain-core<0.2,>=0.1->langchain-google-genai==0.0.6) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from pydantic<3,>=1->langchain-core<0.2,>=0.1->langchain-google-genai==0.0.6) (2.27.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai<0.4.0,>=0.3.1->langchain-google-genai==0.0.6) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai<0.4.0,>=0.3.1->langchain-google-genai==0.0.6) (2.4.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from rsa<5,>=3.1.4->google-auth->google-generativeai<0.4.0,>=0.3.1->langchain-google-genai==0.0.6) (0.6.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-core<0.2,>=0.1->langchain-google-genai==0.0.6) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-core<0.2,>=0.1->langchain-google-genai==0.0.6) (1.3.1)\n",
      "Using cached langchain_google_genai-0.0.6-py3-none-any.whl (15 kB)\n",
      "Using cached google_ai_generativelanguage-0.4.0-py3-none-any.whl (598 kB)\n",
      "Using cached langchain_core-0.1.53-py3-none-any.whl (303 kB)\n",
      "Using cached langsmith-0.1.147-py3-none-any.whl (311 kB)\n",
      "Installing collected packages: langsmith, langchain-core, google-ai-generativelanguage, langchain-google-genai\n",
      "\u001b[2K  Attempting uninstall: langsmith\n",
      "\u001b[2K    Found existing installation: langsmith 0.3.45\n",
      "\u001b[2K    Uninstalling langsmith-0.3.45:\n",
      "\u001b[2K      Successfully uninstalled langsmith-0.3.45\n",
      "\u001b[2K  Attempting uninstall: langchain-core\n",
      "\u001b[2K    Found existing installation: langchain-core 0.3.65\n",
      "\u001b[2K    Uninstalling langchain-core-0.3.65:\n",
      "\u001b[2K      Successfully uninstalled langchain-core-0.3.65\n",
      "\u001b[2K  Attempting uninstall: google-ai-generativelanguage━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [langchain-core]\n",
      "\u001b[2K    Found existing installation: google-ai-generativelanguage 0.3.1\u001b[32m1/4\u001b[0m [langchain-core]\n",
      "\u001b[2K    Uninstalling google-ai-generativelanguage-0.3.1:━━━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [langchain-core]\n",
      "\u001b[2K      Successfully uninstalled google-ai-generativelanguage-0.3.1━\u001b[0m \u001b[32m2/4\u001b[0m [google-ai-generativelanguage]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [langchain-google-genai]e-ai-generativelanguage]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain 0.3.25 requires langchain-core<1.0.0,>=0.3.58, but you have langchain-core 0.1.53 which is incompatible.\n",
      "langchain-community 0.3.25 requires langchain-core<1.0.0,>=0.3.65, but you have langchain-core 0.1.53 which is incompatible.\n",
      "langchain-huggingface 0.2.0 requires langchain-core<1.0.0,>=0.3.59, but you have langchain-core 0.1.53 which is incompatible.\n",
      "langchain-postgres 0.0.14 requires langchain-core<0.4.0,>=0.2.13, but you have langchain-core 0.1.53 which is incompatible.\n",
      "langchain-postgres 0.0.14 requires pgvector<0.4,>=0.2.5, but you have pgvector 0.4.1 which is incompatible.\n",
      "langchain-text-splitters 0.3.8 requires langchain-core<1.0.0,>=0.3.51, but you have langchain-core 0.1.53 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed google-ai-generativelanguage-0.4.0 langchain-core-0.1.53 langchain-google-genai-0.0.6 langsmith-0.1.147\n",
      "Requirement already satisfied: ipywidgets in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (8.1.7)\n",
      "Requirement already satisfied: comm>=0.1.3 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from ipywidgets) (8.36.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from ipywidgets) (4.0.14)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from ipywidgets) (3.0.15)\n",
      "Requirement already satisfied: decorator in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: exceptiongroup in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (1.3.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\n",
      "Requirement already satisfied: stack_data in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: typing_extensions>=4.6 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.13.2)\n",
      "Requirement already satisfied: wcwidth in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "usage: jupyter [-h] [--version] [--config-dir] [--data-dir] [--runtime-dir]\n",
      "               [--paths] [--json] [--debug]\n",
      "               [subcommand]\n",
      "\n",
      "Jupyter: Interactive Computing\n",
      "\n",
      "positional arguments:\n",
      "  subcommand     the subcommand to launch\n",
      "\n",
      "options:\n",
      "  -h, --help     show this help message and exit\n",
      "  --version      show the versions of core jupyter packages and exit\n",
      "  --config-dir   show Jupyter config dir\n",
      "  --data-dir     show Jupyter data dir\n",
      "  --runtime-dir  show Jupyter runtime dir\n",
      "  --paths        show all Jupyter paths. Add --json for machine-readable\n",
      "                 format.\n",
      "  --json         output paths as machine-readable json\n",
      "  --debug        output debug information about paths\n",
      "\n",
      "Available subcommands: dejavu events execute kernel kernelspec lab\n",
      "labextension labhub migrate nbconvert notebook run server troubleshoot trust\n",
      "\n",
      "Jupyter command `jupyter-nbextension` not found.\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y google-generativeai google-ai-generativelanguage langchain-google-genai\n",
    "!pip install google-generativeai==0.3.2\n",
    "!pip install google-ai-generativelanguage==0.3.1\n",
    "!pip install langchain-google-genai==0.0.6\n",
    "\n",
    "!pip install ipywidgets\n",
    "!jupyter nbextension enable --py widgetsnbextension --sys-prefix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: torch 2.7.1\n",
      "Uninstalling torch-2.7.1:\n",
      "  Successfully uninstalled torch-2.7.1\n",
      "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
      "Collecting torch==2.5.1\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torch-2.5.1%2Bcu121-cp310-cp310-linux_x86_64.whl (780.4 MB)\n",
      "Requirement already satisfied: torchvision in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (0.22.1)\n",
      "Requirement already satisfied: torchaudio in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (2.7.1)\n",
      "Requirement already satisfied: filelock in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from torch==2.5.1) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from torch==2.5.1) (4.13.2)\n",
      "Requirement already satisfied: networkx in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from torch==2.5.1) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from torch==2.5.1) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from torch==2.5.1) (2025.5.1)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.5.1)\n",
      "  Using cached https://download.pytorch.org/whl/cu121/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.5.1)\n",
      "  Using cached https://download.pytorch.org/whl/cu121/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.5.1)\n",
      "  Using cached https://download.pytorch.org/whl/cu121/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.5.1)\n",
      "  Using cached https://download.pytorch.org/whl/cu121/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.5.1)\n",
      "  Using cached https://download.pytorch.org/whl/cu121/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.5.1)\n",
      "  Using cached https://download.pytorch.org/whl/cu121/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.5.1)\n",
      "  Using cached https://download.pytorch.org/whl/cu121/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.5.1)\n",
      "  Using cached https://download.pytorch.org/whl/cu121/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.5.1)\n",
      "  Using cached https://download.pytorch.org/whl/cu121/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "Collecting nvidia-nccl-cu12==2.21.5 (from torch==2.5.1)\n",
      "  Using cached https://download.pytorch.org/whl/nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.5.1)\n",
      "  Using cached https://download.pytorch.org/whl/cu121/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "Collecting triton==3.1.0 (from torch==2.5.1)\n",
      "  Using cached https://download.pytorch.org/whl/triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
      "Collecting sympy==1.13.1 (from torch==2.5.1)\n",
      "  Using cached https://download.pytorch.org/whl/sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.5.1) (12.6.85)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from sympy==1.13.1->torch==2.5.1) (1.3.0)\n",
      "Requirement already satisfied: numpy in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from torchvision) (1.26.3)\n",
      "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting torchvision\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torchvision-0.20.1%2Bcu121-cp310-cp310-linux_x86_64.whl (7.3 MB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from torchvision) (10.4.0)\n",
      "INFO: pip is looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting torchaudio\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torchaudio-2.5.1%2Bcu121-cp310-cp310-linux_x86_64.whl (3.4 MB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/imran/miniconda3/envs/genai/lib/python3.10/site-packages (from jinja2->torch==2.5.1) (3.0.2)\n",
      "Installing collected packages: triton, sympy, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchvision, torchaudio\n",
      "\u001b[2K  Attempting uninstall: triton\n",
      "\u001b[2K    Found existing installation: triton 3.3.1\n",
      "\u001b[2K    Uninstalling triton-3.3.1:\n",
      "\u001b[2K      Successfully uninstalled triton-3.3.1\n",
      "\u001b[2K  Attempting uninstall: sympy━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 0/16\u001b[0m [triton]\n",
      "\u001b[2K    Found existing installation: sympy 1.14.0[0m \u001b[32m 0/16\u001b[0m [triton]\n",
      "\u001b[2K    Uninstalling sympy-1.14.0:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/16\u001b[0m [sympy]\n",
      "\u001b[2K      Successfully uninstalled sympy-1.14.0━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/16\u001b[0m [sympy]\n",
      "\u001b[2K  Attempting uninstall: nvidia-nvtx-cu12━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/16\u001b[0m [sympy]\n",
      "\u001b[2K    Found existing installation: nvidia-nvtx-cu12 12.6.77━━━━━\u001b[0m \u001b[32m 1/16\u001b[0m [sympy]\n",
      "\u001b[2K    Uninstalling nvidia-nvtx-cu12-12.6.77:━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/16\u001b[0m [sympy]\n",
      "\u001b[2K      Successfully uninstalled nvidia-nvtx-cu12-12.6.77━━━━━━━\u001b[0m \u001b[32m 1/16\u001b[0m [sympy]\n",
      "\u001b[2K  Attempting uninstall: nvidia-nccl-cu12━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/16\u001b[0m [sympy]\n",
      "\u001b[2K    Found existing installation: nvidia-nccl-cu12 2.26.2━━━━━━\u001b[0m \u001b[32m 1/16\u001b[0m [sympy]\n",
      "\u001b[2K    Uninstalling nvidia-nccl-cu12-2.26.2:━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/16\u001b[0m [sympy]\n",
      "\u001b[2K      Successfully uninstalled nvidia-nccl-cu12-2.26.2━━━━━━━━\u001b[0m \u001b[32m 1/16\u001b[0m [sympy]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cusparse-cu12━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/16\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\u001b[0m \u001b[32m 3/16\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cusparse-cu12-12.5.4.2:━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/16\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2━━\u001b[0m \u001b[32m 3/16\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-curand-cu12━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/16\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-curand-cu12 10.3.7.77━\u001b[0m \u001b[32m 4/16\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-curand-cu12-10.3.7.77:━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/16\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-curand-cu12-10.3.7.77━━━\u001b[0m \u001b[32m 4/16\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cufft-cu12━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/16\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cufft-cu12 11.3.0.4━━━\u001b[0m \u001b[32m 5/16\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cufft-cu12-11.3.0.4:━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/16\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4━━━━━\u001b[0m \u001b[32m 5/16\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-runtime-cu12━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/16\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77m \u001b[32m 6/16\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:━━━━━━━━━━━━\u001b[0m \u001b[32m 6/16\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77[0m \u001b[32m 6/16\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-nvrtc-cu12━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/16\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77[0m \u001b[32m 6/16\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/16\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77━\u001b[0m \u001b[32m 6/16\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-cupti-cu12m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/16\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80[0m \u001b[32m 8/16\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/16\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80━\u001b[0m \u001b[32m 8/16\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cublas-cu120m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/16\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cublas-cu12 12.6.4.1━━\u001b[0m \u001b[32m 9/16\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cublas-cu12-12.6.4.1:━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/16\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1━━━━\u001b[0m \u001b[32m 9/16\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cusolver-cu12[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/16\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\u001b[0m \u001b[32m10/16\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cusolver-cu12-11.7.1.2:m━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/16\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2━━\u001b[0m \u001b[32m10/16\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cudnn-cu1291m╸\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m11/16\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cudnn-cu12 9.5.1.17━━━\u001b[0m \u001b[32m11/16\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cudnn-cu12-9.5.1.17:m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m11/16\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cudnn-cu12-9.5.1.17━━━━━\u001b[0m \u001b[32m11/16\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K  Attempting uninstall: torchvision━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m13/16\u001b[0m [torch]-cudnn-cu12]\n",
      "\u001b[2K    Found existing installation: torchvision 0.22.1[90m━━━━━━━\u001b[0m \u001b[32m13/16\u001b[0m [torch]\n",
      "\u001b[2K    Uninstalling torchvision-0.22.1:\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m13/16\u001b[0m [torch]\n",
      "\u001b[2K      Successfully uninstalled torchvision-0.22.1m\u001b[90m━━━━━━━\u001b[0m \u001b[32m13/16\u001b[0m [torch]\n",
      "\u001b[2K  Attempting uninstall: torchaudio━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m14/16\u001b[0m [torchvision]\n",
      "\u001b[2K    Found existing installation: torchaudio 2.7.1\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m14/16\u001b[0m [torchvision]\n",
      "\u001b[2K    Uninstalling torchaudio-2.7.1:━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m14/16\u001b[0m [torchvision]\n",
      "\u001b[2K      Successfully uninstalled torchaudio-2.7.1m╺\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m14/16\u001b[0m [torchvision]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16/16\u001b[0m [torchaudio]6\u001b[0m [torchaudio]\n",
      "\u001b[1A\u001b[2KSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.21.5 nvidia-nvtx-cu12-12.1.105 sympy-1.13.1 torch-2.5.1+cu121 torchaudio-2.5.1+cu121 torchvision-0.20.1+cu121 triton-3.1.0\n"
     ]
    }
   ],
   "source": [
    "# Uninstall current torch\n",
    "!pip uninstall torch -y\n",
    "\n",
    "# Install PyTorch 2.5.1 and compatible versions\n",
    "!pip install torch==2.5.1 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iblagocDBG0M"
   },
   "source": [
    "# **Import all necessary packages and modules**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "x8rHieyd-Pc4"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "import json\n",
    "import time\n",
    "import logging\n",
    "from typing import List, Dict, Any, Optional\n",
    "from datetime import timedelta\n",
    "\n",
    "import sqlite3  # Added for SQLite fallback\n",
    "import psycopg2\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "import pandas as pd\n",
    "import google.generativeai as genai\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "import pandas as pd\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def safe_api_call(func, max_retries=3, delay=1):\n",
    "    \"\"\"Safe API call with retries\"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            return func()\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Attempt {attempt + 1} failed: {e}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                time.sleep(delay * (2 ** attempt))\n",
    "            else:\n",
    "                return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5dMFC47yA4Pa"
   },
   "source": [
    "# **Set your Google API key** *local we using .env*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "4Ol80x9T_KYF"
   },
   "outputs": [],
   "source": [
    "# Set your Google API key (if not already in environment)\n",
    "if \"GOOGLE_API_KEY\" not in os.environ:\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyAQZcS0H6s3IBrIMyGAw3_tnRaQanFzpBk\"\n",
    "    API_KEY = \"AIzaSyAQZcS0H6s3IBrIMyGAw3_tnRaQanFzpBk\" #\"AIzaSyBz0ERhDhWnh_KO-GWeNqe7S-j8SBmt22k\" #AIzaSyC9H2klWHV9YCHooUPukXvWGztUbacuQMM AIzaSyBazIeacy7eubIZ6J-h6H5DBo2EoJS1gU4\n",
    "    SEARCH_ENGINE_ID = \"94f57e531fc964fd5\"  # Your CSE ID from the HTML code a0fcf4aeb345944e6 f3df791282bb246c7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jNMBqaQqBf7W"
   },
   "source": [
    "# **Set your LangSmith key** *local we using .env*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "nDOd-bfCAzND"
   },
   "outputs": [],
   "source": [
    "# Set your LangSmith API key (optional, for tracing)\n",
    "if \"LANGSMITH_API_KEY\" not in os.environ:\n",
    "    os.environ[\"LANGSMITH_API_KEY\"] = \"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\"\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oU3qScBKCD_i"
   },
   "source": [
    "# **Create the ChatGoogleGenerativeAI instance**  I using gemini-2.0-flash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "VhA59KymAvGK"
   },
   "outputs": [],
   "source": [
    "# # Create the ChatGoogleGenerativeAI instance\n",
    "\n",
    "# llm = ChatGoogleGenerativeAI(\n",
    "#     model=\"gemini-2.0-flash\",\n",
    "#     temperature=0,\n",
    "#     max_tokens=None,\n",
    "#     timeout=None,\n",
    "#     max_retries=2,\n",
    "#     # other params...\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mfm7nZJUCWz4"
   },
   "source": [
    "#  **Calling Our Models or LLM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WLBQShlAAyIf"
   },
   "outputs": [],
   "source": [
    "# # Make a call to the Gemini model\n",
    "# response = llm.invoke(\"Can you explain the concept of 'few-shot learning' in LLMs and its advantages?\")\n",
    "# # Access the generated text\n",
    "# print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Loading KEY from the environment variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set your Google API key (replace with your actual key or use environment variable)\n",
    "if \"GOOGLE_API_KEY\" not in os.environ:\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyAQZcS0H6s3IBrIMyGAw3_tnRaQanFzpBk\" # \"AIzaSyBvYAw9t-xndPUNBJ4EKhWv6_l_nJp6_yo\"\n",
    "\n",
    "# Set your LangSmith key (optional, for tracing)\n",
    "if \"LANGSMITH_API_KEY\" not in os.environ:\n",
    "    os.environ[\"LANGSMITH_API_KEY\"] = \"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\"\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Interactive setup for database URL if not set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_database_url():\n",
    "    \"\"\"Interactive setup for database URL if not set\"\"\"\n",
    "    if os.getenv(\"DATABASE_URL\"):\n",
    "        return os.getenv(\"DATABASE_URL\")\n",
    "    \n",
    "    print(\"\\n🔧 Database Setup Required\")\n",
    "    print(\"   PostgreSQL with vector_user (recommended)\")\n",
    "\n",
    "    print(\"\\nUsing vector_user credentials...\")\n",
    "    host = 'localhost'\n",
    "    port = 5432 \n",
    "    database = 'vector_db' \n",
    "    username = \"vector_user\"\n",
    "    password = \"SecurePassword123!\"\n",
    "        \n",
    "    database_url = f\"postgresql://{username}:{password}@{host}:{port}/{database}\"\n",
    "    os.environ[\"DATABASE_URL\"] = database_url\n",
    "    print(f\"✅ Using: postgresql://vector_user:***@{host}:{port}/{database}\")\n",
    "    return database_url\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handle Rate Limiting for API and **Process Transactions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class RateLimitHandler:\n",
    "    \"\"\"Handle rate limiting for API calls\"\"\"\n",
    "    def __init__(self, requests_per_minute=8):  # Even more conservative\n",
    "        self.requests_per_minute = requests_per_minute\n",
    "        self.request_times = []\n",
    "        self.last_rate_limit_time = 0\n",
    "    \n",
    "    def wait_if_needed(self):\n",
    "        \"\"\"Wait if we're approaching rate limits\"\"\"\n",
    "        current_time = time.time()\n",
    "        \n",
    "        # If we recently hit a rate limit, wait extra time\n",
    "        if current_time - self.last_rate_limit_time < 60:\n",
    "            extra_wait = 60 - (current_time - self.last_rate_limit_time)\n",
    "            if extra_wait > 0:\n",
    "                logger.info(f\"Recent rate limit detected. Extra wait: {extra_wait:.1f} seconds...\")\n",
    "                time.sleep(extra_wait)\n",
    "                current_time = time.time()\n",
    "        \n",
    "        # Remove requests older than 1 minute\n",
    "        self.request_times = [t for t in self.request_times if current_time - t < 60]\n",
    "        \n",
    "        if len(self.request_times) >= self.requests_per_minute:\n",
    "            # Wait until the oldest request is more than 1 minute old\n",
    "            sleep_time = 60 - (current_time - self.request_times[0]) + 2  # +2 seconds buffer\n",
    "            if sleep_time > 0:\n",
    "                logger.info(f\"Proactive rate limit wait: {sleep_time:.1f} seconds...\")\n",
    "                time.sleep(sleep_time)\n",
    "                # Clean up old requests again\n",
    "                current_time = time.time()\n",
    "                self.request_times = [t for t in self.request_times if current_time - t < 60]\n",
    "        \n",
    "        self.request_times.append(current_time)\n",
    "    \n",
    "    def record_rate_limit_hit(self):\n",
    "        \"\"\"Record when we hit a rate limit\"\"\"\n",
    "        self.last_rate_limit_time = time.time()\n",
    "        # Clear recent requests to reset our tracking\n",
    "        self.request_times = []\n",
    "\n",
    "def make_llm_request(llm, message, rate_limiter, max_retries=3):\n",
    "    \"\"\"Make LLM request with custom rate limit handling\"\"\"\n",
    "    rate_limiter.wait_if_needed()\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            return llm.invoke(message)\n",
    "        except Exception as e:\n",
    "            error_str = str(e)\n",
    "            \n",
    "            # Check if it's a rate limit error\n",
    "            if \"ResourceExhausted\" in error_str or \"429\" in error_str or \"quota\" in error_str.lower():\n",
    "                wait_time = 30  # Wait 30 seconds for rate limit errors\n",
    "                print(f\"⏰ Rate limit hit (attempt {attempt + 1}/{max_retries}). Waiting {wait_time} seconds...\")\n",
    "                time.sleep(wait_time)\n",
    "                \n",
    "                if attempt < max_retries - 1:  # Don't wait after the last attempt\n",
    "                    continue\n",
    "            else:\n",
    "                # For other errors, wait shorter time\n",
    "                wait_time = 5 * (attempt + 1)  # 5, 10, 15 seconds\n",
    "                print(f\"⚠️  API error (attempt {attempt + 1}/{max_retries}): {error_str}\")\n",
    "                if attempt < max_retries - 1:\n",
    "                    print(f\"   Retrying in {wait_time} seconds...\")\n",
    "                    time.sleep(wait_time)\n",
    "                    continue\n",
    "            \n",
    "            # If we reach here, it's the final attempt or a non-retryable error\n",
    "            if attempt == max_retries - 1:\n",
    "                raise e\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Process bank transactions with rate limiting and error handling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_bank_transactions(limit: int = 10,batch_size: int = 50000):\n",
    "    \"\"\"Process bank transactions with rate limiting and error handling\"\"\"\n",
    "    #print(f\"\\n🔄 Processing bank transactions (limit: {limit})...\")\n",
    "    \n",
    "    # Initialize rate limiter\n",
    "    rate_limiter = RateLimitHandler(requests_per_minute=10)\n",
    "    \n",
    "    try:\n",
    "        filename = \"bank_transactions_with_vendor_100.csv\"\n",
    "        if not os.path.exists(filename):\n",
    "            print(f\"⚠️  File {filename} not found.\")\n",
    "            return []\n",
    "        \n",
    "        df = pd.read_csv(filename)\n",
    "        print(f\"✅ Loaded {len(df)} transactions\")\n",
    "        \n",
    "        # Limit the dataframe if specified\n",
    "        if limit > 0:\n",
    "            df = df.head(limit)\n",
    "            print(f\"📊 Processing first {len(df)} transactions\")\n",
    "        \n",
    "        # Create LLM instance\n",
    "        llm = ChatGoogleGenerativeAI(\n",
    "            model=\"gemini-2.0-flash\",\n",
    "            temperature=0,\n",
    "            convert_system_message_to_human=True\n",
    "        )\n",
    "        \n",
    "        results = []\n",
    "        failed_transactions = []\n",
    "        \n",
    "        # Process in batches to save progress\n",
    "        for batch_start in range(0, len(df), batch_size):\n",
    "            batch_end = min(batch_start + batch_size, len(df))\n",
    "            batch_df = df.iloc[batch_start:batch_end]\n",
    "            \n",
    "            print(f\"\\n📦 Processing batch {batch_start//batch_size + 1}: transactions {batch_start+1}-{batch_end}\")\n",
    "            \n",
    "            for i, (idx, row) in enumerate(batch_df.iterrows()):\n",
    "                try:\n",
    "                    print(f\"🔄 Processing transaction {idx+1}: {row['Description'][:50]}...\")\n",
    "                    \n",
    "                    # Single message prompt\n",
    "                    message = (\n",
    "                        f\"Categorize this financial transaction into exactly one of these categories: \"\n",
    "                        f\"Education, Health, Groceries, Transportation, Utilities, Entertainment, Shopping, Other\\n\\n\"\n",
    "                        f\"Transaction: {row['Description']} at {row['Vendor']} for ${row['Amount']}\\n\\n\"\n",
    "                        f\"Respond with only the category name, nothing else.\"\n",
    "                    )\n",
    "                    \n",
    "                    # Make request with rate limiting and retry\n",
    "                    response = make_llm_request(llm, message, rate_limiter)\n",
    "                    category = response.content.strip().replace(\"Category:\", \"\").strip()\n",
    "                    \n",
    "                    # Ensure it's a valid category\n",
    "                    valid_categories = ['Education', 'Health', 'Groceries', 'Transportation', \n",
    "                                     'Utilities', 'Entertainment', 'Shopping', 'Other']\n",
    "                    \n",
    "                    if category not in valid_categories:\n",
    "                        for valid_cat in valid_categories:\n",
    "                            if valid_cat.lower() in category.lower():\n",
    "                                category = valid_cat\n",
    "                                break\n",
    "                        else:\n",
    "                            category = 'Other'\n",
    "                    \n",
    "                    results.append({\n",
    "                        \"transaction_id\": idx + 1,\n",
    "                        \"description\": row[\"Description\"],\n",
    "                        \"vendor\": row[\"Vendor\"],\n",
    "                        \"amount\": row[\"Amount\"],\n",
    "                        \"category\": category\n",
    "                    })\n",
    "                    \n",
    "                    print(f\"✅ Category: {category}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    error_msg = str(e)\n",
    "                    print(f\"❌ Error processing transaction {idx+1}: {error_msg}\")\n",
    "                    \n",
    "                    # Handle specific rate limit errors\n",
    "                    if \"ResourceExhausted\" in error_msg or \"429\" in error_msg or \"quota\" in error_msg.lower():\n",
    "                        print(\"⏰ Rate limit detected. Recording for future avoidance...\")\n",
    "                        rate_limiter.record_rate_limit_hit()\n",
    "                        # Add to failed list for potential retry\n",
    "                        failed_transactions.append((idx, row))\n",
    "                    \n",
    "                    results.append({\n",
    "                        \"transaction_id\": idx + 1,\n",
    "                        \"description\": row[\"Description\"],\n",
    "                        \"vendor\": row[\"Vendor\"],\n",
    "                        \"amount\": row[\"Amount\"],\n",
    "                        \"category\": \"Error\"\n",
    "                    })\n",
    "            \n",
    "        \n",
    "        # Retry failed transactions once\n",
    "        if failed_transactions:\n",
    "            print(f\"\\n🔄 Retrying {len(failed_transactions)} failed transactions...\")\n",
    "            print(\"⏰ Waiting 60 seconds before retry to ensure rate limits are reset...\")\n",
    "            time.sleep(60)  # Wait before retrying\n",
    "            \n",
    "            for idx, row in failed_transactions:\n",
    "                try:\n",
    "                    message = (\n",
    "                        f\"Categorize this financial transaction into exactly one of these categories: \"\n",
    "                        f\"Education, Health, Groceries, Transportation, Utilities, Entertainment, Shopping, Other\\n\\n\"\n",
    "                        f\"Transaction: {row['Description']} at {row['Vendor']} for ${row['Amount']}\\n\\n\"\n",
    "                        f\"Respond with only the category name, nothing else.\"\n",
    "                    )\n",
    "                    \n",
    "                    response = make_llm_request(llm, message, rate_limiter)\n",
    "                    category = response.content.strip().replace(\"Category:\", \"\").strip()\n",
    "                    \n",
    "                    # Update the result\n",
    "                    for result in results:\n",
    "                        if result[\"transaction_id\"] == idx + 1:\n",
    "                            result[\"category\"] = category if category in valid_categories else 'Other'\n",
    "                            break\n",
    "                    \n",
    "                    print(f\"✅ Retry successful for transaction {idx+1}: {category}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"❌ Retry failed for transaction {idx+1}: {e}\")\n",
    "        \n",
    "        print(f\"\\n✅ Processing complete! Processed {len(results)} transactions\")\n",
    "        print(results)\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Transaction processing failed: {e}\")\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Simple in-memory vector store for testing**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from typing import List, Dict, Optional\n",
    "import math\n",
    "\n",
    "class SimpleVectorStore:\n",
    "    \"\"\"Simple in-memory vector store for testing\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.documents = []\n",
    "        self.embeddings = []\n",
    "        \n",
    "        # Configure device and load SentenceTransformer model\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        print(f\"🔧 Using device: {self.device}\")\n",
    "        \n",
    "        self.model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2', device=self.device)\n",
    "        \n",
    "        print(\"✅ SimpleVectorStore initialized with SentenceTransformer\")\n",
    "    \n",
    "    def get_embedding(self, text: str) -> List[float]:\n",
    "        \"\"\"Generate embedding using SentenceTransformer\"\"\"\n",
    "        try:\n",
    "            # Generate embedding and convert to list\n",
    "            embedding = self.model.encode(text, convert_to_tensor=False)\n",
    "            return embedding.tolist()\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error generating embedding: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def add_document(self, text: str, metadata: Optional[Dict] = None):\n",
    "        \"\"\"Add document to the store\"\"\"\n",
    "        embedding = self.get_embedding(text)\n",
    "        if embedding:\n",
    "            self.documents.append({\"text\": text, \"metadata\": metadata or {}})\n",
    "            self.embeddings.append(embedding)\n",
    "            print(f\"✅ Added document: '{text[:50]}...'\")\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def search_similar(self, query: str, limit: int = 3):\n",
    "        \"\"\"Search for similar documents\"\"\"\n",
    "        query_embedding = self.get_embedding(query)\n",
    "        if not query_embedding:\n",
    "            return []\n",
    "        \n",
    "        def cosine_similarity(a, b):\n",
    "            dot_product = sum(x * y for x, y in zip(a, b))\n",
    "            magnitude_a = math.sqrt(sum(x * x for x in a))\n",
    "            magnitude_b = math.sqrt(sum(x * x for x in b))\n",
    "            return dot_product / (magnitude_a * magnitude_b) if magnitude_a and magnitude_b else 0\n",
    "        \n",
    "        similarities = []\n",
    "        for i, embedding in enumerate(self.embeddings):\n",
    "            similarity = cosine_similarity(query_embedding, embedding)\n",
    "            similarities.append((i, similarity))\n",
    "        \n",
    "        # Sort by similarity and get top results\n",
    "        similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "        results = []\n",
    "        \n",
    "        for i, similarity in similarities[:limit]:\n",
    "            results.append({\n",
    "                \"content\": self.documents[i][\"text\"],\n",
    "                \"metadata\": self.documents[i][\"metadata\"],\n",
    "                \"similarity\": similarity\n",
    "            })\n",
    "        \n",
    "        return results\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Vector store with PostgreSQL database**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from typing import Union, List, Dict, Any, Optional\n",
    "from datetime import datetime\n",
    "import math\n",
    "from sqlalchemy import create_engine,text\n",
    "\n",
    "\n",
    "\n",
    "class DatabaseVectorStore:\n",
    "    \"\"\"Vector store with PostgreSQL database (requires pgvector extension)\"\"\"\n",
    "    \n",
    "    def __init__(self, database_url: Optional[str] = None):\n",
    "        \"\"\"Initialize with database connection\"\"\"\n",
    "        self.engine = create_engine(database_url)\n",
    "        self.database_url = database_url or os.getenv(\"DATABASE_URL\", \"postgresql://vector_user:SecurePassword123!@localhost:5432/vector_db\")\n",
    "        self.embedding_dimensions = 1536  # Required by your schema\n",
    "        \n",
    "        # Configure device and load SentenceTransformer model\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        print(f\"🔧 Using device: {self.device}\")\n",
    "        \n",
    "        self.model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2', device=self.device)\n",
    "        self.model_dimensions = 384  # all-MiniLM-L6-v2 dimensions\n",
    "        \n",
    "        # Test database connection\n",
    "        if not self._test_connection():\n",
    "            raise ConnectionError(\"Failed to connect to database\")\n",
    "        \n",
    "        print(\"✅ DatabaseVectorStore initialized with SentenceTransformer\")\n",
    "    \n",
    "    def get_embedding(self, text: Union[str, dict]) -> List[float]:\n",
    "        \"\"\"Generate embedding using SentenceTransformer with dimension padding\"\"\"\n",
    "        # Handle different input types\n",
    "        if isinstance(text, dict):\n",
    "            # Convert dict to string representation\n",
    "            text_content = str(text)\n",
    "        elif isinstance(text, str):\n",
    "            text_content = text\n",
    "        else:\n",
    "            print(f\"❌ Unsupported input type: {type(text)}\")\n",
    "            return []\n",
    "        \n",
    "        if not text_content or not text_content.strip():\n",
    "            return []\n",
    "        \n",
    "        text_content = text_content.replace(\"\\n\", \" \").strip()\n",
    "        \n",
    "        def _generate_embedding():\n",
    "            # Generate embedding and convert to list\n",
    "            embedding = self.model.encode(text_content, convert_to_tensor=False)\n",
    "            return embedding.tolist()\n",
    "        \n",
    "        base_embedding = safe_api_call(_generate_embedding)\n",
    "        if base_embedding:\n",
    "            # Pad the embedding to match required dimensions\n",
    "            if len(base_embedding) < self.embedding_dimensions:\n",
    "                # Calculate how many times to repeat the base embedding\n",
    "                repeat_times = self.embedding_dimensions // len(base_embedding)\n",
    "                remainder = self.embedding_dimensions % len(base_embedding)\n",
    "                \n",
    "                # Create padded embedding\n",
    "                padded_embedding = base_embedding * repeat_times\n",
    "                if remainder:\n",
    "                    padded_embedding.extend(base_embedding[:remainder])\n",
    "                \n",
    "                print(f\"✅ Padded embedding from {len(base_embedding)} to {len(padded_embedding)} dimensions\")\n",
    "                return padded_embedding\n",
    "            \n",
    "            return base_embedding\n",
    "        else:\n",
    "            print(f\"❌ Embedding generation failed for text: {str(text_content)[:50]}...\")\n",
    "            return []\n",
    "\n",
    "    def _normalize_embedding(self, embedding: List[float]) -> List[float]:\n",
    "        \"\"\"Normalize embedding vector to unit length\"\"\"\n",
    "        import math\n",
    "        magnitude = math.sqrt(sum(x * x for x in embedding))\n",
    "        if magnitude > 0:\n",
    "            return [x / magnitude for x in embedding]\n",
    "        return embedding\n",
    "\n",
    "    def _test_connection(self) -> bool:\n",
    "        \"\"\"Test database connection and check for required tables\"\"\"\n",
    "        try:\n",
    "            conn = psycopg2.connect(self.database_url)\n",
    "            cursor = conn.cursor()\n",
    "            \n",
    "            # Check PostgreSQL version\n",
    "            cursor.execute(\"SELECT version();\")\n",
    "            version = cursor.fetchone()[0]\n",
    "            print(f\"✅ Connected to: {version[:50]}...\")\n",
    "            \n",
    "            cursor.close()\n",
    "            conn.close()\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Database connection failed: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def create_table(self) -> bool:\n",
    "        \"\"\"Create required tables if they don't exist\"\"\"\n",
    "        try:\n",
    "            conn = psycopg2.connect(self.database_url)\n",
    "            cursor = conn.cursor()\n",
    "            \n",
    "            # Enable vector extension\n",
    "            cursor.execute(\"CREATE EXTENSION IF NOT EXISTS vector;\")\n",
    "            \n",
    "            # Create temp_transactions table\n",
    "            cursor.execute(\"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS temp_transactions (\n",
    "                    id SERIAL PRIMARY KEY,\n",
    "                    content TEXT NOT NULL,\n",
    "                    embedding vector(1536),\n",
    "                    metadata JSONB,\n",
    "                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "                );\n",
    "            \"\"\")\n",
    "            \n",
    "            # Create master_vector table\n",
    "            cursor.execute(\"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS master_vector (\n",
    "                    id SERIAL PRIMARY KEY,\n",
    "                    content TEXT NOT NULL,\n",
    "                    embedding vector(1536),\n",
    "                    metadata JSONB,\n",
    "                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "                );\n",
    "            \"\"\")\n",
    "            \n",
    "            # Create search_history table\n",
    "            cursor.execute(\"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS search_history (\n",
    "                    id SERIAL PRIMARY KEY,\n",
    "                    content TEXT NOT NULL,\n",
    "                    embedding vector(1536),\n",
    "                    metadata JSONB,\n",
    "                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "                );\n",
    "            \"\"\")\n",
    "            \n",
    "            # Create indexes for better performance\n",
    "            cursor.execute(\"\"\"\n",
    "                CREATE INDEX IF NOT EXISTS temp_transactions_embedding_idx \n",
    "                ON temp_transactions USING ivfflat (embedding vector_cosine_ops) \n",
    "                WITH (lists = 100);\n",
    "            \"\"\")\n",
    "            \n",
    "            cursor.execute(\"\"\"\n",
    "                CREATE INDEX IF NOT EXISTS master_vector_embedding_idx \n",
    "                ON master_vector USING ivfflat (embedding vector_cosine_ops) \n",
    "                WITH (lists = 100);\n",
    "            \"\"\")\n",
    "            \n",
    "            cursor.execute(\"\"\"\n",
    "                CREATE INDEX IF NOT EXISTS search_history_embedding_idx \n",
    "                ON search_history USING ivfflat (embedding vector_cosine_ops) \n",
    "                WITH (lists = 100);\n",
    "            \"\"\")\n",
    "            \n",
    "            conn.commit()\n",
    "            cursor.close()\n",
    "            conn.close()\n",
    "            \n",
    "            print(\"✅ All tables and indexes created successfully\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Failed to create tables: {e}\")\n",
    "            if 'conn' in locals():\n",
    "                conn.rollback()\n",
    "                cursor.close()\n",
    "                conn.close()\n",
    "            return False\n",
    "\n",
    "    def add_document(self, text: Union[str, dict], metadata: Optional[Dict[str, Any]] = None, table_name: str = \"temp_transactions\") -> bool:\n",
    "        \"\"\"Add document to specified table (convenience method)\"\"\"\n",
    "        if table_name == \"temp_transactions\":\n",
    "            return self.insert_temp_transaction(text, metadata)\n",
    "        elif table_name == \"master_vector\":\n",
    "            return self.insert_master_vector(text, metadata)\n",
    "        elif table_name == \"search_history\":\n",
    "            return self.insert_search_history(text, metadata)\n",
    "        else:\n",
    "            print(f\"❌ Invalid table name: {table_name}\")\n",
    "            return False\n",
    "    \n",
    "    def insert_temp_transaction(self, content: Union[str, dict], metadata: Optional[Dict[str, Any]] = None) -> bool:\n",
    "        \"\"\"Insert document into temp_transactions table - now handles both strings and dicts\"\"\"\n",
    "        # Convert content to string if it's a dict\n",
    "        if isinstance(content, dict):\n",
    "            # Create a meaningful string representation\n",
    "            content_str = f\"Transaction: {content.get('Description', 'N/A')} at {content.get('Vendor', 'N/A')} for ${content.get('Amount', 'N/A')}\"\n",
    "            # Add the original dict to metadata\n",
    "            if metadata is None:\n",
    "                metadata = {}\n",
    "            metadata.update(content)\n",
    "        else:\n",
    "            content_str = str(content)\n",
    "        \n",
    "        # Fixed syntax error: was self.(content_str), now self.get_embedding(content_str)\n",
    "        embedding = self.get_embedding(content_str)\n",
    "        if not embedding or len(embedding) != self.embedding_dimensions:\n",
    "            print(f\"❌ Invalid embedding: expected {self.embedding_dimensions} dimensions, got {len(embedding) if embedding else 0}\")\n",
    "            return False\n",
    "        \n",
    "        # Normalize the embedding before insertion\n",
    "        embedding = self._normalize_embedding(embedding)\n",
    "        \n",
    "        try:\n",
    "            conn = psycopg2.connect(self.database_url)\n",
    "            cursor = conn.cursor()\n",
    "            \n",
    "            insert_sql = \"\"\"\n",
    "            INSERT INTO temp_transactions (content, embedding, metadata)\n",
    "            VALUES (%s, %s::vector, %s)\n",
    "            \"\"\"\n",
    "            \n",
    "            cursor.execute(insert_sql, (content_str, str(embedding), json.dumps(metadata or {})))\n",
    "            conn.commit()\n",
    "            \n",
    "            print(f\"✅ Temp transaction inserted: '{content_str[:50]}...'\")\n",
    "            cursor.close()\n",
    "            conn.close()\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Failed to insert temp transaction: {e}\")\n",
    "            if 'conn' in locals():\n",
    "                conn.rollback()\n",
    "                cursor.close()\n",
    "                conn.close()\n",
    "            return False\n",
    "    def get_master_vector_count(self):\n",
    "        with self.engine.connect() as connection:\n",
    "            result = connection.execute(text(\"SELECT COUNT(*) FROM master_vector\"))\n",
    "            count = result.scalar()  # Returns single value\n",
    "            return count if count else 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def insert_master_vector(self, content: Union[str, dict], metadata: Optional[Dict[str, Any]] = None) -> bool:\n",
    "        \"\"\"Insert document into master_vector table, avoiding duplicates based on Category, Entity/Keyword, and Type\"\"\"\n",
    "        # Step 1: Normalize input\n",
    "        if isinstance(content, dict):\n",
    "            category = content.get('Category', 'N/A')\n",
    "            entity = content.get('Entity/Keyword', 'N/A')\n",
    "            txn_type = content.get('Type', 'N/A')\n",
    "            content_str = f\"Transaction: {category} at {entity} for ${txn_type}\"\n",
    "            metadata = {**(metadata or {}), **content}\n",
    "        else:\n",
    "            print(\"❌ Skipping insert: content is not a dictionary, cannot check for duplicates.\")\n",
    "            return False\n",
    "    \n",
    "        # Step 2: Check for duplicate\n",
    "        try:\n",
    "            with psycopg2.connect(self.database_url) as conn:\n",
    "                with conn.cursor() as cursor:\n",
    "                    duplicate_check_sql = \"\"\"\n",
    "                    SELECT 1 FROM master_vector\n",
    "                    WHERE \n",
    "                        metadata->>'Category' = %s AND \n",
    "                        metadata->>'Entity/Keyword' = %s AND \n",
    "                        metadata->>'Type' = %s\n",
    "                    LIMIT 1\n",
    "                    \"\"\"\n",
    "                    cursor.execute(duplicate_check_sql, (category, entity, txn_type))\n",
    "                    if cursor.fetchone():\n",
    "                        print(f\"⚠️ Duplicate found: {category}, {entity}, {txn_type} — skipping insert.\")\n",
    "                        return False\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error during duplicate check: {e}\")\n",
    "            return False\n",
    "    \n",
    "        # Step 3: Generate and validate embedding\n",
    "        embedding = self.get_embedding(content_str)\n",
    "        if not embedding or len(embedding) != self.embedding_dimensions:\n",
    "            print(f\"❌ Invalid embedding: expected {self.embedding_dimensions} dimensions, got {len(embedding) if embedding else 0}\")\n",
    "            return False\n",
    "    \n",
    "        embedding = self._normalize_embedding(embedding)\n",
    "        embedding_str = '[' + ','.join(map(str, embedding)) + ']'\n",
    "    \n",
    "        # Step 4: Insert\n",
    "        insert_sql = \"\"\"\n",
    "        INSERT INTO master_vector (content, embedding, metadata)\n",
    "        VALUES (%s, %s::vector, %s)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            with psycopg2.connect(self.database_url) as conn:\n",
    "                with conn.cursor() as cursor:\n",
    "                    cursor.execute(insert_sql, (content_str, embedding_str, json.dumps(metadata or {})))\n",
    "                conn.commit()\n",
    "            print(f\"✅ Master vector inserted: '{content_str[:50]}...'\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Failed to insert master vector: {e}\")\n",
    "            return False\n",
    "\n",
    "    def insert_search_history(self, query: Union[str, dict], metadata: Optional[Dict[str, Any]] = None) -> bool:\n",
    "        \"\"\"Insert search query into search_history table\"\"\"\n",
    "        # Convert query to string if it's a dict\n",
    "        if isinstance(query, dict):\n",
    "            query_str = str(query)\n",
    "            if metadata is None:\n",
    "                metadata = {}\n",
    "            metadata.update(query)\n",
    "        else:\n",
    "            query_str = str(query)\n",
    "            \n",
    "        embedding = self.get_embedding(query_str)\n",
    "        if not embedding or len(embedding) != self.embedding_dimensions:\n",
    "            print(f\"❌ Invalid embedding: expected {self.embedding_dimensions} dimensions, got {len(embedding) if embedding else 0}\")\n",
    "            return False\n",
    "            \n",
    "        # Normalize the embedding before insertion\n",
    "        embedding = self._normalize_embedding(embedding)\n",
    "        \n",
    "        try:\n",
    "            conn = psycopg2.connect(self.database_url)\n",
    "            cursor = conn.cursor()\n",
    "            \n",
    "            # Add timestamp to metadata if not present\n",
    "            if metadata is None:\n",
    "                metadata = {}\n",
    "            if 'query_time' not in metadata:\n",
    "                metadata['query_time'] = datetime.now().isoformat()\n",
    "            \n",
    "            insert_sql = \"\"\"\n",
    "            INSERT INTO search_history (content, embedding, metadata)\n",
    "            VALUES (%s, %s::vector, %s)\n",
    "            \"\"\"\n",
    "            \n",
    "            cursor.execute(insert_sql, (query_str, str(embedding), json.dumps(metadata)))\n",
    "            conn.commit()\n",
    "            \n",
    "            print(f\"✅ Search history inserted: '{query_str[:50]}...'\")\n",
    "            cursor.close()\n",
    "            conn.close()\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Failed to insert search history: {e}\")\n",
    "            if 'conn' in locals():\n",
    "                conn.rollback()\n",
    "                cursor.close()\n",
    "                conn.close()\n",
    "            return False\n",
    "    \n",
    "    def search_similar(self, query: str, table_name: str = \"temp_transactions\", limit: int = 3) -> List[Dict]:\n",
    "        \"\"\"Search for similar documents in specified table\"\"\"\n",
    "        if table_name not in ['master_vector', 'search_history','temp_transactions']:\n",
    "            print(f\"❌ Invalid table name: {table_name}\")\n",
    "            return []\n",
    "            \n",
    "        query_embedding = self.get_embedding(query)\n",
    "        if not query_embedding:\n",
    "            return []\n",
    "        \n",
    "        # Normalize query embedding\n",
    "        query_embedding = self._normalize_embedding(query_embedding)\n",
    "        \n",
    "        try:\n",
    "            conn = psycopg2.connect(self.database_url)\n",
    "            cursor = conn.cursor()\n",
    "            \n",
    "            search_sql = f\"\"\"\n",
    "            SELECT content, metadata, \n",
    "                   1 - (embedding <=> %s::vector) as similarity\n",
    "            FROM {table_name}\n",
    "            ORDER BY embedding <=> %s::vector\n",
    "            LIMIT %s\n",
    "            \"\"\"\n",
    "            \n",
    "            cursor.execute(search_sql, (str(query_embedding), str(query_embedding), limit))\n",
    "            results = cursor.fetchall()\n",
    "            \n",
    "            formatted_results = []\n",
    "            for row in results:\n",
    "                formatted_results.append({\n",
    "                    \"content\": row[0],\n",
    "                    \"metadata\": row[1],\n",
    "                    \"similarity\": float(row[2])\n",
    "                })\n",
    "            \n",
    "            print(f\"✅ Found {len(formatted_results)} similar documents in {table_name}\")\n",
    "            cursor.close()\n",
    "            conn.close()\n",
    "            return formatted_results\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Search failed: {e}\")\n",
    "            if 'conn' in locals():\n",
    "                cursor.close()\n",
    "                conn.close()\n",
    "            return []\n",
    "\n",
    "    def process_file(self, file_path: str, table_name: str = \"temp_transactions\") -> bool:\n",
    "        \"\"\"Process and insert data from a CSV file\"\"\"\n",
    "        try:\n",
    "            if not os.path.exists(file_path):\n",
    "                print(f\"❌ File not found: {file_path}\")\n",
    "                return False\n",
    "            \n",
    "            # Read the CSV file\n",
    "            df = pd.read_csv(file_path)\n",
    "            print(f\"✅ Loaded {len(df)} records from {file_path}\")\n",
    "            \n",
    "            # Convert to dictionary records\n",
    "            records = df.to_dict(orient='records')\n",
    "            \n",
    "            success_count = 0\n",
    "            for i, record in enumerate(records):\n",
    "                print(f\"🔄 Processing record {i+1}/{len(records)}...\")\n",
    "                \n",
    "                if self.add_document(record, {\"source\": file_path, \"row_id\": i}, table_name):\n",
    "                    success_count += 1\n",
    "                \n",
    "                # Rate limiting\n",
    "                time.sleep(0.5)\n",
    "            \n",
    "            print(f\"✅ Successfully processed {success_count}/{len(records)} records\")\n",
    "            return success_count == len(records)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Failed to process file {file_path}: {e}\")\n",
    "            return False\n",
    "\n",
    "    def find_best_classification_match(self, text: str, similarity_threshold: float = 0.7) -> Dict:\n",
    "        \"\"\"\n",
    "        Find the best classification match from master_vector and search_history tables.\n",
    "        Priority: master_vector first, then search_history if no match found.\n",
    "        \"\"\"\n",
    "        result = {\n",
    "            \"classification_category\": None,\n",
    "            \"reason_source\": None,\n",
    "            \"confidence_score\": 0.0\n",
    "        }\n",
    "        \n",
    "        # First, search in master_vector table\n",
    "        master_matches = self.search_similar(text, table_name=\"master_vector\", limit=1)\n",
    "        \n",
    "        if master_matches and len(master_matches) > 0:\n",
    "            best_match = master_matches[0]\n",
    "            if best_match[\"similarity\"] >= similarity_threshold:\n",
    "                # Extract classification category from metadata\n",
    "                metadata = best_match.get(\"metadata\", {})\n",
    "                if isinstance(metadata, dict):\n",
    "                    classification = metadata.get(\"classification_category\") or metadata.get(\"category\") or metadata.get(\"Entity/Keyword\")\n",
    "                else:\n",
    "                    # If metadata is a string, try to parse it or use content\n",
    "                    classification = self._extract_category_from_content(best_match[\"content\"])\n",
    "                \n",
    "                result = {\n",
    "                    \"classification_category\": classification,\n",
    "                    \"reason_source\": \"master_vector\",\n",
    "                    \"confidence_score\": best_match[\"similarity\"]\n",
    "                }\n",
    "                return result\n",
    "        \n",
    "        # If no match in master_vector, search in search_history\n",
    "        history_matches = self.search_similar(text, table_name=\"search_history\", limit=1)\n",
    "        \n",
    "        if history_matches and len(history_matches) > 0:\n",
    "            best_match = history_matches[0]\n",
    "            if best_match[\"similarity\"] >= similarity_threshold:\n",
    "                # Extract classification category from metadata\n",
    "                metadata = best_match.get(\"metadata\", {})\n",
    "                if isinstance(metadata, dict):\n",
    "                    classification = metadata.get(\"classification_category\") or metadata.get(\"category\")\n",
    "                else:\n",
    "                    # If metadata is a string, try to parse it or use content\n",
    "                    classification = self._extract_category_from_content(best_match[\"content\"])\n",
    "                \n",
    "                result = {\n",
    "                    \"classification_category\": classification,\n",
    "                    \"reason_source\": \"search_history\",\n",
    "                    \"confidence_score\": best_match[\"similarity\"]\n",
    "                }\n",
    "        \n",
    "        return result\n",
    "\n",
    "    def _extract_category_from_content(self, content: str) -> str:\n",
    "        \"\"\"\n",
    "        Extract category from content string if metadata doesn't contain it.\n",
    "        This is a fallback method - adjust based on your data structure.\n",
    "        \"\"\"\n",
    "        if not content:\n",
    "            return \"Unknown\"\n",
    "        \n",
    "        # Simple heuristic - you may need to adjust this based on your data format\n",
    "        content_lower = content.lower()\n",
    "        \n",
    "        # Common transaction categories\n",
    "        if any(word in content_lower for word in ['grocery', 'food', 'restaurant', 'dining']):\n",
    "            return \"Food & Dining\"\n",
    "        elif any(word in content_lower for word in ['gas', 'fuel', 'station']):\n",
    "            return \"Transportation\"\n",
    "        elif any(word in content_lower for word in ['pharmacy', 'medical', 'health']):\n",
    "            return \"Healthcare\"\n",
    "        elif any(word in content_lower for word in ['amazon', 'walmart', 'target', 'shopping']):\n",
    "            return \"Shopping\"\n",
    "        elif any(word in content_lower for word in ['bank', 'atm', 'transfer']):\n",
    "            return \"Banking\"\n",
    "        else:\n",
    "            return \"Other\"\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Combine 'Description' and 'Vendor' for embedding\n",
    "def get_text_to_embed(row):\n",
    "    desc = str(row['Description']).strip()\n",
    "    vendor = str(row['Vendor']).strip()\n",
    "    return f\"{desc} - {vendor}\" if vendor else desc\n",
    "\n",
    "# Main processing code\n",
    "def process_transactions_with_classification(input_file):\n",
    "    # Load CSV with only required columns\n",
    "    test_docs = pd.read_csv(input_file, usecols=['TransactionID', 'Description', 'Vendor'])\n",
    "    print(\"📁 Loaded transaction data:\")\n",
    "    print(test_docs.head())\n",
    "    \n",
    "    # Initialize vector store\n",
    "    database_url = setup_database_url()\n",
    "    vector_store = DatabaseVectorStore(database_url)\n",
    "    \n",
    "    # Check if master_vector has data\n",
    "    master_count = vector_store.get_master_vector_count()\n",
    "    print(f\"📊 Master vector table contains {master_count} entries\")\n",
    "    \n",
    "    # Initialize lists for new data\n",
    "    embeddings = []\n",
    "    classifications = []\n",
    "    reason_sources = []\n",
    "    confidence_scores = []\n",
    "    \n",
    "    # Process each transaction\n",
    "    print(\"🔄 Processing transactions...\")\n",
    "    for _, row in tqdm(test_docs.iterrows(), total=len(test_docs), desc=\"Processing transactions\"):\n",
    "        # Generate text for embedding\n",
    "        text_input = get_text_to_embed(row)\n",
    "        \n",
    "        # Generate embedding\n",
    "        emb = vector_store.get_embedding(text_input)\n",
    "        embeddings.append(emb)\n",
    "        \n",
    "        # Find classification match\n",
    "        classification_result = vector_store.find_best_classification_match(text_input)\n",
    "        print(classification_result)\n",
    "        \n",
    "        classifications.append(classification_result[\"classification_category\"])\n",
    "        reason_sources.append(classification_result[\"reason_source\"])\n",
    "        confidence_scores.append(classification_result[\"confidence_score\"])\n",
    "    \n",
    "    # print(classifications)\n",
    "    # Add all new columns to dataframe\n",
    "    # test_docs[\"embedding\"] = embeddings\n",
    "    test_docs[\"classification_category\"] = classifications\n",
    "    test_docs[\"reason_source\"] = reason_sources\n",
    "    test_docs[\"confidence_score\"] = confidence_scores\n",
    "    \n",
    "    # Add embedding length for verification\n",
    "    #test_docs[\"embedding_len\"] = test_docs[\"embedding\"].apply(lambda x: len(x) if isinstance(x, list) else 0)\n",
    "    \n",
    "    # Display results\n",
    "    print(\"\\n📋 Processing Results:\")\n",
    "    display_columns = [\"TransactionID\", \"Description\", \"Vendor\", \"classification_category\", \n",
    "                      \"reason_source\", \"confidence_score\"]\n",
    "    print(test_docs[display_columns].head(10))\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(\"\\n📊 Classification Summary:\")\n",
    "    classification_summary = test_docs.groupby(['classification_category', 'reason_source']).size().reset_index(name='count')\n",
    "    print(classification_summary)\n",
    "    \n",
    "    # Save results\n",
    "    output_file = 'bank_transactions_classified.csv'\n",
    "    test_docs.to_csv(output_file, index=False)\n",
    "    print(f\"💾 Results saved to {output_file}\")\n",
    "    \n",
    "    return test_docs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Main function to demonstrate functionalit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Main function to demonstrate functionality\"\"\"\n",
    "    print(\"🚀 Starting GenAI Vector Store Demo...\")\n",
    "    \n",
    "    \n",
    "    # Process bank transactions (if file exists)\n",
    "    # transaction_results = process_bank_transactions()\n",
    "    transaction_results =process_bank_transactions(limit=50, batch_size=5)\n",
    "    \n",
    "    # # Test simple vector store (always works)\n",
    "    # print(\"\\n\" + \"=\"*50)\n",
    "    # print(\"TESTING SIMPLE VECTOR STORE (In-Memory)\")\n",
    "    # print(\"=\"*50)\n",
    "    \n",
    "    try:\n",
    "        simple_store = SimpleVectorStore()\n",
    "        #simple_store.test_functionality()\n",
    "    except Exception as e:\n",
    "        print(f\"❌ SimpleVectorStore failed: {e}\")\n",
    "    \n",
    "    # Setup database URL interactively if not set\n",
    "    database_url = setup_database_url()\n",
    "\n",
    "      \n",
    "    if database_url and database_url.startswith(\"postgresql\"):\n",
    "        # Test PostgreSQL vector store\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"TESTING POSTGRESQL VECTOR STORE\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        try:\n",
    "            db_store = DatabaseVectorStore(database_url)\n",
    "            \n",
    "            # Create table\n",
    "            if db_store.create_table():\n",
    "            \n",
    "                test_docs_master=pd.read_csv('Master_data.csv')\n",
    "                csv_count = len(test_docs_master)\n",
    "\n",
    "                test_docs_master=test_docs_master.to_dict(orient='records')\n",
    "                table_count = db_store.get_master_vector_count()  # Assume this returns an int\n",
    "                # print(table_count,'------------------->imran<--------------')\n",
    "                if csv_count > table_count:\n",
    "                    print(\"New records detected. Inserting into DB...\")\n",
    "                    for doc_master in test_docs_master:\n",
    "                        db_store.insert_master_vector(doc_master, {\"source\": \"demo\"})\n",
    "                else:\n",
    "                    print(\"No new records to insert. Running in test mode.\")\n",
    "\n",
    "                test_docs = pd.read_csv('bank_transactions_with_vendor_100.csv', usecols=['TransactionID', 'Description', 'Vendor'])\n",
    "                print(test_docs.head())\n",
    "                input_file='bank_transactions_with_vendor_100.csv'\n",
    "                processed_data = process_transactions_with_classification(input_file)\n",
    "                \n",
    "                # Search\n",
    "                results = db_store.search_similar(\"I want to retrieve all transaction details related to Zomato, including a clear summary of the total inflow and outflow amounts, categorized by credit and debit. Additionally, the summary should include transaction models such as UPT, NTF, etc.\", limit=2)\n",
    "                # if results:\n",
    "                #     print(\"✅ Database vector store test successful!\")\n",
    "                #     for result in results:\n",
    "                #         print(f\"   Similarity: {result['similarity']:.3f} - {result['content'][:50]}...\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"❌ DatabaseVectorStore failed: {e}\")\n",
    "            print(\"💡 Try using SQLite option or check PostgreSQL setup\")\n",
    "    \n",
    "    else:\n",
    "        print(\"⚠️  Database tests skipped\")\n",
    "    \n",
    "    print(\"\\n✅ Demo completed!\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Function Call**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting GenAI Vector Store Demo...\n",
      "✅ Loaded 20 transactions\n",
      "📊 Processing first 20 transactions\n",
      "\n",
      "📦 Processing batch 1: transactions 1-5\n",
      "🔄 Processing transaction 1: UPI Payment to Zomato...\n",
      "✅ Category: Entertainment\n",
      "🔄 Processing transaction 2: EMI payment - ICICI Personal Loan...\n",
      "✅ Category: Other\n",
      "🔄 Processing transaction 3: UPI Payment to Zomato...\n",
      "✅ Category: Entertainment\n",
      "🔄 Processing transaction 4: EMI payment - ICICI Personal Loan...\n",
      "✅ Category: Other\n",
      "🔄 Processing transaction 5: EMI payment - ICICI Personal Loan...\n",
      "✅ Category: Other\n",
      "\n",
      "📦 Processing batch 2: transactions 6-10\n",
      "🔄 Processing transaction 6: UPI Payment to Zomato...\n",
      "✅ Category: Entertainment\n",
      "🔄 Processing transaction 7: Interest credited on SB account...\n",
      "✅ Category: Other\n",
      "🔄 Processing transaction 8: Received from Mahesh via UPI...\n",
      "✅ Category: Other\n",
      "🔄 Processing transaction 9: Interest credited on SB account...\n",
      "✅ Category: Other\n",
      "🔄 Processing transaction 10: EMI payment - ICICI Personal Loan...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Proactive rate limit wait: 51.1 seconds...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Category: Other\n",
      "\n",
      "📦 Processing batch 3: transactions 11-15\n",
      "🔄 Processing transaction 11: UPI Payment to Zomato...\n",
      "✅ Category: Entertainment\n",
      "🔄 Processing transaction 12: UPI Payment to Zomato...\n",
      "✅ Category: Entertainment\n",
      "🔄 Processing transaction 13: Received from Mahesh via UPI...\n",
      "✅ Category: Other\n",
      "🔄 Processing transaction 14: Received from Mahesh via UPI...\n",
      "✅ Category: Other\n",
      "🔄 Processing transaction 15: EMI payment - ICICI Personal Loan...\n",
      "✅ Category: Other\n",
      "\n",
      "📦 Processing batch 4: transactions 16-20\n",
      "🔄 Processing transaction 16: UPI Payment to Zomato...\n",
      "✅ Category: Entertainment\n",
      "🔄 Processing transaction 17: EMI payment - ICICI Personal Loan...\n",
      "✅ Category: Other\n",
      "🔄 Processing transaction 18: Interest credited on SB account...\n",
      "✅ Category: Other\n",
      "🔄 Processing transaction 19: EMI payment - ICICI Personal Loan...\n",
      "✅ Category: Other\n",
      "🔄 Processing transaction 20: EMI payment - ICICI Personal Loan...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Category: Other\n",
      "\n",
      "✅ Processing complete! Processed 20 transactions\n",
      "[{'transaction_id': 1, 'description': 'UPI Payment to Zomato', 'vendor': 'Zomato', 'amount': '431', 'category': 'Entertainment'}, {'transaction_id': 2, 'description': 'EMI payment - ICICI Personal Loan', 'vendor': 'ICICI Personal Loan', 'amount': '1,770', 'category': 'Other'}, {'transaction_id': 3, 'description': 'UPI Payment to Zomato', 'vendor': 'Zomato', 'amount': '134', 'category': 'Entertainment'}, {'transaction_id': 4, 'description': 'EMI payment - ICICI Personal Loan', 'vendor': 'ICICI Personal Loan', 'amount': '4,725', 'category': 'Other'}, {'transaction_id': 5, 'description': 'EMI payment - ICICI Personal Loan', 'vendor': 'ICICI Personal Loan', 'amount': '1,203', 'category': 'Other'}, {'transaction_id': 6, 'description': 'UPI Payment to Zomato', 'vendor': 'Zomato', 'amount': '147', 'category': 'Entertainment'}, {'transaction_id': 7, 'description': 'Interest credited on SB account', 'vendor': 'Interest', 'amount': '32', 'category': 'Other'}, {'transaction_id': 8, 'description': 'Received from Mahesh via UPI', 'vendor': 'Received', 'amount': '838.62', 'category': 'Other'}, {'transaction_id': 9, 'description': 'Interest credited on SB account', 'vendor': 'Interest', 'amount': '50', 'category': 'Other'}, {'transaction_id': 10, 'description': 'EMI payment - ICICI Personal Loan', 'vendor': 'ICICI Personal Loan', 'amount': '1,100', 'category': 'Other'}, {'transaction_id': 11, 'description': 'UPI Payment to Zomato', 'vendor': 'Zomato', 'amount': '299', 'category': 'Entertainment'}, {'transaction_id': 12, 'description': 'UPI Payment to Zomato', 'vendor': 'Zomato', 'amount': '249', 'category': 'Entertainment'}, {'transaction_id': 13, 'description': 'Received from Mahesh via UPI', 'vendor': 'Received', 'amount': '1,000', 'category': 'Other'}, {'transaction_id': 14, 'description': 'Received from Mahesh via UPI', 'vendor': 'Received', 'amount': '711', 'category': 'Other'}, {'transaction_id': 15, 'description': 'EMI payment - ICICI Personal Loan', 'vendor': 'ICICI Personal Loan', 'amount': '1,395.04', 'category': 'Other'}, {'transaction_id': 16, 'description': 'UPI Payment to Zomato', 'vendor': 'Zomato', 'amount': '147', 'category': 'Entertainment'}, {'transaction_id': 17, 'description': 'EMI payment - ICICI Personal Loan', 'vendor': 'ICICI Personal Loan', 'amount': '3,195', 'category': 'Other'}, {'transaction_id': 18, 'description': 'Interest credited on SB account', 'vendor': 'Interest', 'amount': '30', 'category': 'Other'}, {'transaction_id': 19, 'description': 'EMI payment - ICICI Personal Loan', 'vendor': 'ICICI Personal Loan', 'amount': '2,299', 'category': 'Other'}, {'transaction_id': 20, 'description': 'EMI payment - ICICI Personal Loan', 'vendor': 'ICICI Personal Loan', 'amount': '1,200', 'category': 'Other'}]\n",
      "🔧 Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ SimpleVectorStore initialized with SentenceTransformer\n",
      "\n",
      "🔧 Database Setup Required\n",
      "   PostgreSQL with vector_user (recommended)\n",
      "\n",
      "Using vector_user credentials...\n",
      "✅ Using: postgresql://vector_user:***@localhost:5432/vector_db\n",
      "\n",
      "==================================================\n",
      "TESTING POSTGRESQL VECTOR STORE\n",
      "==================================================\n",
      "🔧 Using device: cuda\n",
      "✅ Connected to: PostgreSQL 16.9 (Ubuntu 16.9-1.pgdg24.04+1) on x86...\n",
      "✅ DatabaseVectorStore initialized with SentenceTransformer\n",
      "✅ All tables and indexes created successfully\n",
      "New records detected. Inserting into DB...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07bd17fcc7514c7fb44159a4d4e2627d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Padded embedding from 384 to 1536 dimensions\n",
      "✅ Master vector inserted: 'Transaction: Credit Card Payment at HDFC Bank Cred...'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65142fe47d924d49be75cced16d1b5dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Padded embedding from 384 to 1536 dimensions\n",
      "✅ Master vector inserted: 'Transaction: Loan Repayment at ICICI Loan EMI for ...'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fe8254984d940df9bc5c50f97d2105a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Padded embedding from 384 to 1536 dimensions\n",
      "✅ Master vector inserted: 'Transaction: Credit Card Payment at Amazon Pay ICI...'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da64ad55d6a14603a0b2296e1c8e4075",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Padded embedding from 384 to 1536 dimensions\n",
      "✅ Master vector inserted: 'Transaction: Insurance at SBI Life Insurance for $...'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ca4b180911648c0819c0eed1d8c5f39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Padded embedding from 384 to 1536 dimensions\n",
      "✅ Master vector inserted: 'Transaction: Salary Credit at HDFC Salary for $Inf...'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6fae46640f8486e84ff07b0c624559a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Padded embedding from 384 to 1536 dimensions\n",
      "✅ Master vector inserted: 'Transaction: Fund Transfer at IMPS Transfer for $I...'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96d5069147f54e9cb3c50ad7fb3c8548",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Padded embedding from 384 to 1536 dimensions\n",
      "✅ Master vector inserted: 'Transaction: Fund Transfer at NEFT Transfer for $I...'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bd8997b431344ad874ea79d8e4f0fd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Padded embedding from 384 to 1536 dimensions\n",
      "✅ Master vector inserted: 'Transaction: UPI Transaction at UPI Payment for $I...'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e699b524589045219a304d01e32a387e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Padded embedding from 384 to 1536 dimensions\n",
      "✅ Master vector inserted: 'Transaction: Loan Repayment at Bajaj Finserv EMI f...'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df495685f20f442bb6d54adaa3ecf666",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Padded embedding from 384 to 1536 dimensions\n",
      "✅ Master vector inserted: 'Transaction: Utility Payment at EB Bill TNEB for $...'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c92308c6afc4e85b96e5d92564c8136",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Padded embedding from 384 to 1536 dimensions\n",
      "✅ Master vector inserted: 'Transaction: Credit Card Payment at Axis Bank Cred...'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4665e87b2de7425b8faa813bb14a3052",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Padded embedding from 384 to 1536 dimensions\n",
      "✅ Master vector inserted: 'Transaction: Insurance at LIC Premium for $Outflow...'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "069efcacdafb43298d2f62b8c1db7609",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Padded embedding from 384 to 1536 dimensions\n",
      "✅ Master vector inserted: 'Transaction: Interest Credit at Interest Cr for $I...'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e13b5efbc7441009bd1d0809b45e6c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Padded embedding from 384 to 1536 dimensions\n",
      "✅ Master vector inserted: 'Transaction: Investment at Mutual Fund SIP for $Ou...'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fb56b02dde444ef90f770273af51494",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Padded embedding from 384 to 1536 dimensions\n",
      "✅ Master vector inserted: 'Transaction: Wallet Recharge at Paytm Wallet for $...'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55aa8f224fcc4b8580d17a906f44cbdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Padded embedding from 384 to 1536 dimensions\n",
      "✅ Master vector inserted: 'Transaction: UPI Transaction at Google Pay for $In...'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c026dfa58e054e9e8c58b2aeefc90925",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Padded embedding from 384 to 1536 dimensions\n",
      "✅ Master vector inserted: 'Transaction: UPI Transaction at PhonePe for $Inflo...'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d27539d0d234863919d7e223145c2c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Padded embedding from 384 to 1536 dimensions\n",
      "✅ Master vector inserted: 'Transaction: Stock Investment at Zerodha for $Outf...'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f19c8a3b07e548da987733c4365932ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Padded embedding from 384 to 1536 dimensions\n",
      "✅ Master vector inserted: 'Transaction: Mutual Fund at CAMS for $Outflow...'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdb04a9c12394aaa95049f246e1071c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Padded embedding from 384 to 1536 dimensions\n",
      "✅ Master vector inserted: 'Transaction: Utility Payment at Airtel Recharge fo...'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1db9954f76d44e20b08e751bb31c8377",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Padded embedding from 384 to 1536 dimensions\n",
      "✅ Master vector inserted: 'Transaction: Credit Card Payment at Flipkart Axis ...'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df2bfec8d1bb483f9ea5d7a714ce97b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Padded embedding from 384 to 1536 dimensions\n",
      "✅ Master vector inserted: 'Transaction: Refund at Credit Card Refund for $Inf...'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8270d89de49e4f03a874a3de9e5d3325",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Padded embedding from 384 to 1536 dimensions\n",
      "✅ Master vector inserted: 'Transaction: Transport at Uber India for $Outflow...'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "486a2dd6f30c4ae889e2dabfca8b304b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Padded embedding from 384 to 1536 dimensions\n",
      "✅ Master vector inserted: 'Transaction: Transport at Ola Cabs for $Outflow...'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cba733491a6489895388f633bdbeb57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Padded embedding from 384 to 1536 dimensions\n",
      "✅ Master vector inserted: 'Transaction: Food Delivery at Swiggy for $Outflow...'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "896c5e54f64b46f88dbf7896997f9be2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Padded embedding from 384 to 1536 dimensions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Master vector inserted: 'Transaction: ICICI at ICICI Personal Loan for $Inf...'\n",
      "  TransactionID                        Description               Vendor\n",
      "0       T781784              UPI Payment to Zomato               Zomato\n",
      "1       T781785  EMI payment - ICICI Personal Loan  ICICI Personal Loan\n",
      "2       T781786              UPI Payment to Zomato               Zomato\n",
      "3       T781787  EMI payment - ICICI Personal Loan  ICICI Personal Loan\n",
      "4       T781788  EMI payment - ICICI Personal Loan  ICICI Personal Loan\n",
      "📁 Loaded transaction data:\n",
      "  TransactionID                        Description               Vendor\n",
      "0       T781784              UPI Payment to Zomato               Zomato\n",
      "1       T781785  EMI payment - ICICI Personal Loan  ICICI Personal Loan\n",
      "2       T781786              UPI Payment to Zomato               Zomato\n",
      "3       T781787  EMI payment - ICICI Personal Loan  ICICI Personal Loan\n",
      "4       T781788  EMI payment - ICICI Personal Loan  ICICI Personal Loan\n",
      "🔧 Using device: cuda\n",
      "✅ Connected to: PostgreSQL 16.9 (Ubuntu 16.9-1.pgdg24.04+1) on x86...\n",
      "✅ DatabaseVectorStore initialized with SentenceTransformer\n",
      "📊 Master vector table contains 26 entries\n",
      "🔄 Processing transactions...\n",
      "❌ DatabaseVectorStore failed: name 'tqdm' is not defined\n",
      "💡 Try using SQLite option or check PostgreSQL setup\n",
      "\n",
      "✅ Demo completed!\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Google Search**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "from typing import Dict, List, Optional\n",
    "from requests.exceptions import HTTPError\n",
    "\n",
    "class GoogleCustomSearch:\n",
    "    def __init__(self, api_key: str, search_engine_id: str):\n",
    "        self.api_key = api_key\n",
    "        self.search_engine_id = search_engine_id\n",
    "        self.base_url = \"https://www.googleapis.com/customsearch/v1\"\n",
    "    \n",
    "    def search(self, query: str, num_results: int = 10, start_index: int = 1, \n",
    "           site_search: Optional[str] = None, exact_terms: Optional[str] = None,\n",
    "           exclude_terms: Optional[str] = None, file_type: Optional[str] = None,\n",
    "           date_restrict: Optional[str] = None) -> Dict:\n",
    "    \n",
    "        params = {\n",
    "            'key': self.api_key,\n",
    "            'cx': self.search_engine_id,\n",
    "            'q': query,\n",
    "            'num': min(num_results, 10),\n",
    "            'start': start_index\n",
    "        }\n",
    "    \n",
    "        if site_search:\n",
    "            params['siteSearch'] = site_search\n",
    "        if exact_terms:\n",
    "            params['exactTerms'] = exact_terms\n",
    "        if exclude_terms:\n",
    "            params['excludeTerms'] = exclude_terms\n",
    "        if file_type:\n",
    "            params['fileType'] = file_type\n",
    "        if date_restrict:\n",
    "            params['dateRestrict'] = date_restrict\n",
    "    \n",
    "        max_retries = 5\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                response = requests.get(self.base_url, params=params)\n",
    "                response.raise_for_status()\n",
    "                return response.json()\n",
    "            except requests.exceptions.HTTPError as e:\n",
    "                if response.status_code == 429:\n",
    "                    wait = 2 ** attempt\n",
    "                    print(f\"Rate limit hit. Retrying in {wait} seconds...\")\n",
    "                    time.sleep(wait)\n",
    "                else:\n",
    "                    print(f\"HTTP error occurred: {e}\")\n",
    "                    break\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                print(f\"Error making request: {e}\")\n",
    "                time.sleep(3)\n",
    "                break\n",
    "        return {}\n",
    "    \n",
    "        \n",
    "    def get_search_results(self, query: str, max_results: int = 10) -> List[Dict]:\n",
    "        results = []\n",
    "        start_index = 1\n",
    "        attempt = 1\n",
    "        \n",
    "        while len(results) < max_results:\n",
    "            try:\n",
    "                batch_size = min(10, max_results - len(results))\n",
    "                response = self.search(query, num_results=batch_size, start_index=start_index)\n",
    "                \n",
    "                if 'items' not in response:\n",
    "                    break\n",
    "                \n",
    "                for item in response['items']:\n",
    "                    if len(results) >= max_results:\n",
    "                        break\n",
    "                    \n",
    "                    result = {\n",
    "                        'title': item.get('title', ''),\n",
    "                        'link': item.get('link', ''),\n",
    "                        'snippet': item.get('snippet', ''),\n",
    "                        'display_link': item.get('displayLink', ''),\n",
    "                        'formatted_url': item.get('formattedUrl', '')\n",
    "                    }\n",
    "                    results.append(result)\n",
    "                \n",
    "                start_index += batch_size\n",
    "                attempt = 1  # Reset attempt after success\n",
    "            \n",
    "            except HTTPError as http_err:\n",
    "                if response.status_code == 429:\n",
    "                    print(f\"Rate limit hit (attempt {attempt})... Retrying after backoff.\")\n",
    "                    time.sleep(2 ** attempt)\n",
    "                    attempt += 1\n",
    "                else:\n",
    "                    print(f\"HTTP error occurred: {http_err}\")\n",
    "                    break\n",
    "            except Exception as err:\n",
    "                print(f\"Unexpected error: {err}\")\n",
    "                break\n",
    "            \n",
    "            if 'queries' not in response or 'nextPage' not in response['queries']:\n",
    "                break\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def print_results(self, query: str, max_results: int = 10):\n",
    "        results = self.get_search_results(query, max_results)\n",
    "        \n",
    "        print(f\"\\nSearch Results for: '{query}'\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        for i, result in enumerate(results, 1):\n",
    "            print(f\"\\n{i}. {result['title']}\")\n",
    "            print(f\"   URL: {result['link']}\")\n",
    "            print(f\"   {result['snippet']}\")\n",
    "            print(\"-\" * 40)\n",
    "        \n",
    "        if not results:\n",
    "            print(\"No results found.\")\n",
    "\n",
    "    def has_transaction_mention(self, query: str) -> bool:\n",
    "        results = self.get_search_results(query, max_results=1)\n",
    "        return bool(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Google Search Function Calling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing Transaction 1 ---\n",
      "Searching for: AMAZON.COM PURCHASE\n",
      "HTTP error occurred: 403 Client Error: Forbidden for url: https://www.googleapis.com/customsearch/v1?key=AIzaSyAQZcS0H6s3IBrIMyGAw3_tnRaQanFzpBk&cx=94f57e531fc964fd5&q=AMAZON.COM+PURCHASE+company&num=3&start=1\n",
      "Detected Transaction Presence via Search: FALSE\n",
      "\n",
      "--- Processing Transaction 2 ---\n",
      "Searching for: Starbucks\n",
      "HTTP error occurred: 403 Client Error: Forbidden for url: https://www.googleapis.com/customsearch/v1?key=AIzaSyAQZcS0H6s3IBrIMyGAw3_tnRaQanFzpBk&cx=94f57e531fc964fd5&q=Starbucks+company&num=3&start=1\n",
      "Detected Transaction Presence via Search: FALSE\n",
      "\n",
      "--- Processing Transaction 3 ---\n",
      "Searching for: UBER TECHNOLOGIES\n",
      "HTTP error occurred: 403 Client Error: Forbidden for url: https://www.googleapis.com/customsearch/v1?key=AIzaSyAQZcS0H6s3IBrIMyGAw3_tnRaQanFzpBk&cx=94f57e531fc964fd5&q=UBER+TECHNOLOGIES+company&num=3&start=1\n",
      "Detected Transaction Presence via Search: FALSE\n",
      "\n",
      "--- Processing Transaction 4 ---\n",
      "Searching for: Flipkart UPI\n",
      "HTTP error occurred: 403 Client Error: Forbidden for url: https://www.googleapis.com/customsearch/v1?key=AIzaSyAQZcS0H6s3IBrIMyGAw3_tnRaQanFzpBk&cx=94f57e531fc964fd5&q=Flipkart+UPI+company&num=3&start=1\n",
      "Detected Transaction Presence via Search: FALSE\n",
      "\n",
      "--- Processing Transaction 5 ---\n",
      "Searching for: EMI payment - ICICI Personal Loan\n",
      "HTTP error occurred: 403 Client Error: Forbidden for url: https://www.googleapis.com/customsearch/v1?key=AIzaSyAQZcS0H6s3IBrIMyGAw3_tnRaQanFzpBk&cx=94f57e531fc964fd5&q=EMI+payment+-+ICICI+Personal+Loan+company&num=3&start=1\n",
      "Detected Transaction Presence via Search: FALSE\n",
      "\n",
      "--- Processing Transaction 6 ---\n",
      "Searching for: UPI Payment to Zomato\n",
      "HTTP error occurred: 403 Client Error: Forbidden for url: https://www.googleapis.com/customsearch/v1?key=AIzaSyAQZcS0H6s3IBrIMyGAw3_tnRaQanFzpBk&cx=94f57e531fc964fd5&q=UPI+Payment+to+Zomato+company&num=3&start=1\n",
      "Detected Transaction Presence via Search: FALSE\n",
      "\n",
      "--- Processing Transaction 7 ---\n",
      "Searching for: MONTHLY SUBSCRIPTION\n",
      "HTTP error occurred: 403 Client Error: Forbidden for url: https://www.googleapis.com/customsearch/v1?key=AIzaSyAQZcS0H6s3IBrIMyGAw3_tnRaQanFzpBk&cx=94f57e531fc964fd5&q=MONTHLY+SUBSCRIPTION+company&num=3&start=1\n",
      "Detected Transaction Presence via Search: FALSE\n",
      "\n",
      "All enriched transactions:\n",
      "{'transaction_id': 1, 'description': 'AMAZON.COM PURCHASE', 'vendor': 'Unknown Vendor', 'amount': 45.99, 'category': 'Miscellaneous', 'confidence_score': 0.5}\n",
      "{'transaction_id': 2, 'description': 'STARBUCKS COFFEE', 'vendor': 'Starbucks', 'amount': 12.5, 'category': 'Miscellaneous', 'confidence_score': 0.5}\n",
      "{'transaction_id': 3, 'description': 'Unknown Transaction', 'vendor': 'UBER TECHNOLOGIES', 'amount': 18.75, 'category': 'Miscellaneous', 'confidence_score': 0.5}\n",
      "{'transaction_id': 4, 'description': 'Flipkart UPI', 'vendor': 'Unknown Vendor', 'amount': 250.0, 'category': 'Miscellaneous', 'confidence_score': 0.5}\n",
      "{'transaction_id': 5, 'description': 'EMI payment - ICICI Personal Loan', 'vendor': 'Unknown Vendor', 'amount': 2000.0, 'category': 'Miscellaneous', 'confidence_score': 0.5}\n",
      "{'transaction_id': 6, 'description': 'UPI Payment to Zomato', 'vendor': 'Unknown Vendor', 'amount': 340.0, 'category': 'Miscellaneous', 'confidence_score': 0.5}\n",
      "{'transaction_id': 7, 'description': 'MONTHLY SUBSCRIPTION', 'vendor': 'Unknown Vendor', 'amount': 9.99, 'category': 'Miscellaneous', 'confidence_score': 0.5}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    import google.generativeai as genai\n",
    "    import json\n",
    "\n",
    "    # Replace with your actual API keys and import your GoogleCustomSearch client\n",
    "    # from your_module import GoogleCustomSearch, API_KEY, SEARCH_ENGINE_ID\n",
    "\n",
    "    genai.configure(api_key=API_KEY)\n",
    "    model = genai.GenerativeModel('gemini-2.0-flash')\n",
    "\n",
    "    sample_transactions = [\n",
    "        {\"Description\": \"AMAZON.COM PURCHASE\", \"Vendor\": \"\", \"Amount\": 45.99},\n",
    "        {\"Description\": \"STARBUCKS COFFEE\", \"Vendor\": \"Starbucks\", \"Amount\": 12.50},\n",
    "        {\"Description\": \"\", \"Vendor\": \"UBER TECHNOLOGIES\", \"Amount\": 18.75},\n",
    "        {\"Description\": \"Flipkart UPI\", \"Vendor\": \"\", \"Amount\": 250.00},\n",
    "        {\"Description\": \"EMI payment - ICICI Personal Loan\", \"Vendor\": \"\", \"Amount\": 2000.00},\n",
    "        {\"Description\": \"UPI Payment to Zomato\", \"Vendor\": \"\", \"Amount\": 340.00},\n",
    "        {\"Description\": \"MONTHLY SUBSCRIPTION\", \"Vendor\": \"\", \"Amount\": 9.99}\n",
    "    ]\n",
    "\n",
    "    search_client = GoogleCustomSearch(API_KEY, SEARCH_ENGINE_ID)\n",
    "    enriched_transactions = []\n",
    "\n",
    "    general_categorization_prompt = \"\"\"\n",
    "    You are a financial transaction categorization expert.\n",
    "    \n",
    "    Your task is to categorize transactions based on their description and vendor information.\n",
    "    Consider the context carefully and assign each transaction into an appropriate category such as Education, Health, Groceries, Utilities, Transportation, Entertainment, Financial, etc.\n",
    "    \n",
    "    For example:\n",
    "    - Transactions related to school, college, university, or school fees fall under \"Education\".\n",
    "    - Transactions related to operations, surgery, injury fall under \"Health\".\n",
    "    - Transactions related to Amazon, eBay, Walmart, Alibaba, Shopify, Etsy, Target, Flipkart, Rakuten, and Best Buy. under \"E-Commerce or Shopoinng\".\n",
    "    - Similarly, classify other transactions appropriately based on description and vendor.\n",
    "    \n",
    "    For each transaction, provide a JSON response with the following structure:\n",
    "    {\n",
    "        \"category\": \"string\",\n",
    "        \"type\": \"string\",          # One of \"Inflow\", \"Outflow\", or \"Inflow-Outflow\"\n",
    "        \"confidence\": float,       # A confidence score between 0 and 1\n",
    "        \"explanation\": \"string\"    # A brief explanation for the classification\n",
    "    }\n",
    "    \n",
    "    Make sure your response is a valid JSON object matching the above format exactly.\n",
    "    \n",
    "    Example response:\n",
    "    {\n",
    "        \"category\": \"Groceries\",\n",
    "        \"type\": \"Outflow\",\n",
    "        \"confidence\": 0.95,\n",
    "        \"explanation\": \"Transaction matches grocery store pattern based on description and vendor.\"\n",
    "    }\n",
    "    \"\"\"\n",
    "\n",
    "    for idx, row in enumerate(sample_transactions):\n",
    "        description = row.get(\"Description\", \"\").strip()\n",
    "        vendor = row.get(\"Vendor\", \"\").strip()\n",
    "        amount = row.get(\"Amount\", 0)\n",
    "        search_term = vendor or description or \"Unknown\"\n",
    "\n",
    "        print(f\"\\n--- Processing Transaction {idx + 1} ---\")\n",
    "        print(f\"Searching for: {search_term}\")\n",
    "\n",
    "        # Search vendor or description context\n",
    "        search_results = search_client.get_search_results(f\"{search_term} company\", max_results=3)\n",
    "        snippet_text = \" \".join([res.get(\"snippet\", \"\") for res in search_results]).lower()\n",
    "\n",
    "        # Heuristic: determine if it's a known transaction or vendor\n",
    "        has_transaction = any(keyword in snippet_text for keyword in [\n",
    "            \"transaction\", \"payment\", \"transfer\", \"credited\", \"debited\", \"charge\", \"refund\",\n",
    "            \"reversal\", \"settlement\", \"invoice\", \"billed\", \"fee\", \"fine\", \"penalty\", \"adjustment\",\n",
    "            \"upi\", \"imps\", \"neft\", \"rtgs\", \"ach\", \"qr\", \"nfc\", \"gateway\", \"netbanking\",\n",
    "            \"wallet\", \"upi-collect\", \"upi-id\", \"scan\", \"pos\", \"atm\", \"card\", \"credit card\", \"debit card\",\n",
    "            \"loan\", \"emi\", \"installment\", \"interest\", \"mutual fund\", \"sip\", \"nps\", \"insurance\",\n",
    "            \"lic\", \"equity\", \"dividend\", \"stock\", \"investment\", \"pension\", \"brokerage\", \"buy\", \"sell\",\n",
    "            \"salary\", \"wages\", \"bonus\", \"incentive\", \"payout\", \"stipend\", \"reimbursement\", \"commission\",\n",
    "            \"purchase\", \"order\", \"subscription\", \"membership\", \"renewal\", \"plan\", \"ecommerce\", \"checkout\",\n",
    "            \"rent\", \"maintenance\", \"bill\", \"utility\", \"electricity\", \"water\", \"gas\", \"mobile\", \"internet\", \"broadband\", \"tv\", \"dth\", \"fastag\", \"toll\",\n",
    "            \"recharge\", \"topup\", \"cashback\", \"reward\", \"donation\", \"charity\", \"transfer to\", \"transfer from\",\n",
    "            \"upi-ref\", \"utr\", \"ref no\", \"txn id\", \"txn\"\n",
    "        ])\n",
    "\n",
    "        print(\"Detected Transaction Presence via Search:\", \"TRUE\" if has_transaction else \"FALSE\")\n",
    "\n",
    "        if not has_transaction:\n",
    "            enriched_transactions.append({\n",
    "                \"transaction_id\": idx + 1,\n",
    "                \"description\": description or \"Unknown Transaction\",\n",
    "                \"vendor\": vendor or \"Unknown Vendor\",\n",
    "                \"amount\": amount,\n",
    "                \"category\": \"Miscellaneous\",\n",
    "                \"confidence_score\": 0.5,\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        # --- Gemini Enrichment ---\n",
    "\n",
    "        # Infer description if missing\n",
    "        if not description:\n",
    "            prompt_desc = f\"\"\"\n",
    "            Given the vendor name: \"{vendor}\", and online information: \"{snippet_text}\",\n",
    "            generate a concise transaction description (3–5 words).\n",
    "            Only return the description. No other text.\n",
    "            \"\"\"\n",
    "            try:\n",
    "                response = model.generate_content(prompt_desc)\n",
    "                description = response.text.strip()\n",
    "            except Exception:\n",
    "                description = f\"{vendor} Transaction\"\n",
    "\n",
    "        # Infer vendor if missing\n",
    "        if not vendor:\n",
    "            prompt_vendor = f\"\"\"\n",
    "            Based on this transaction description: \"{description}\" and search information: \"{snippet_text}\",\n",
    "            identify the most likely vendor or company name.\n",
    "            Return only the name. No explanation.\n",
    "            \"\"\"\n",
    "            try:\n",
    "                response = model.generate_content(prompt_vendor)\n",
    "                vendor = response.text.strip()\n",
    "            except Exception:\n",
    "                vendor = \"Unknown Vendor\"\n",
    "\n",
    "        # Classify transaction with the generalized prompt and safe JSON parsing\n",
    "        prompt_category = f\"\"\"\n",
    "        {general_categorization_prompt}\n",
    "        \n",
    "        Please categorize this transaction:\n",
    "        Description: {description}\n",
    "        Vendor: {vendor}\n",
    "        Amount: ${amount}\n",
    "        \"\"\"\n",
    "        try:\n",
    "            response = model.generate_content(prompt_category)\n",
    "            raw_response = response.text.strip()\n",
    "\n",
    "            # Extract JSON substring between first '{' and last '}'\n",
    "            json_start = raw_response.find(\"{\")\n",
    "            json_end = raw_response.rfind(\"}\")\n",
    "\n",
    "            if json_start != -1 and json_end != -1:\n",
    "                json_text = raw_response[json_start:json_end + 1]\n",
    "                classification = json.loads(json_text)\n",
    "            else:\n",
    "                classification = {}\n",
    "\n",
    "            category = classification.get(\"category\", \"Miscellaneous\")\n",
    "            confidence_score = classification.get(\"confidence\", 0.5)\n",
    "        except Exception as e:\n",
    "            print(f\"Gemini categorization error: {e}\")\n",
    "            print(f\"Raw response was: {raw_response if 'raw_response' in locals() else 'No response'}\")\n",
    "            category = \"Miscellaneous\"\n",
    "            confidence_score = 0.5\n",
    "\n",
    "        # If category is 'Merchandise', refine it based on vendor\n",
    "        if category.lower() == \"merchandise\":\n",
    "            prompt_vendor_category = f\"\"\"\n",
    "            The transaction was classified as 'Merchandise'.\n",
    "            Based on the vendor name: \"{vendor}\", suggest a more specific transaction category such as\n",
    "            Electronics, Apparel, Grocery, Books, or others.\n",
    "            \n",
    "            Respond only with the category name.\n",
    "            \"\"\"\n",
    "            try:\n",
    "                response = model.generate_content(prompt_vendor_category)\n",
    "                vendor_category = response.text.strip()\n",
    "                if vendor_category:\n",
    "                    category = vendor_category\n",
    "            except Exception as e:\n",
    "                print(f\"Error refining category based on vendor: {e}\")\n",
    "\n",
    "        # Amazon check (optional)\n",
    "        prompt_amazon = f\"\"\"\n",
    "        Is this transaction related to Amazon or its subsidiaries (e.g., AWS, Whole Foods, Kindle, Twitch)?\n",
    "        \n",
    "        Description: {description}\n",
    "        Vendor: {vendor}\n",
    "        Amount: ${amount}\n",
    "        \n",
    "        Online context suggests Amazon reference: {\"amazon\" in snippet_text}\n",
    "        \n",
    "        Respond only with TRUE or FALSE\n",
    "        \"\"\"\n",
    "        try:\n",
    "            response = model.generate_content(prompt_amazon)\n",
    "            # Optionally capture or use response.text.strip() if needed\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        # Save results\n",
    "        enriched_transactions.append({\n",
    "            \"transaction_id\": idx + 1,\n",
    "            \"description\": description,\n",
    "            \"vendor\": vendor,\n",
    "            \"amount\": amount,\n",
    "            \"category\": category,\n",
    "            \"confidence_score\": confidence_score,\n",
    "        })\n",
    "\n",
    "        print(f\"Description: {description}\")\n",
    "        print(f\"Vendor: {vendor}\")\n",
    "        print(f\"Category: {category} | Confidence: {confidence_score}\")\n",
    "\n",
    "    # Optionally print all enriched transactions at the end\n",
    "    print(\"\\nAll enriched transactions:\")\n",
    "    for tx in enriched_transactions:\n",
    "        print(tx)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
